{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - An√°lise Estat√≠stica das Intera√ß√µes\n",
    "\n",
    "Este notebook implementa a **Etapa 4** do pipeline SINKT: an√°lise estat√≠stica completa dos dados de intera√ß√£o gerados.\n",
    "\n",
    "## Objetivo\n",
    "Analisar padr√µes, distribui√ß√µes e m√©tricas dos dados de intera√ß√£o para validar qualidade.\n",
    "\n",
    "## Sa√≠da\n",
    "- `data/output/analysis_report.json`: Relat√≥rio completo de an√°lise estat√≠stica\n",
    "- `data/output/metrics_summary.json`: Resumo de m√©tricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de Todos os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados carregados:\n",
      "  - Perfis: 6\n",
      "  - Estudantes: 100\n",
      "  - Intera√ß√µes: 4450\n"
     ]
    }
   ],
   "source": [
    "# Carregar todos os dados\n",
    "with open('data/output/notebooks/geracao_perfis/profiles.json', 'r', encoding='utf-8') as f:\n",
    "    profiles_data = json.load(f)\n",
    "profiles = profiles_data['profiles']\n",
    "\n",
    "with open('data/output/notebooks/geracao_estudantes/students.json', 'r', encoding='utf-8') as f:\n",
    "    students_data = json.load(f)\n",
    "students = students_data['students']\n",
    "\n",
    "with open('data/output/interactions.json', 'r', encoding='utf-8') as f:\n",
    "    interactions_data = json.load(f)\n",
    "interactions = interactions_data['interactions']\n",
    "\n",
    "print(f\"‚úÖ Dados carregados:\")\n",
    "print(f\"  - Perfis: {len(profiles)}\")\n",
    "print(f\"  - Estudantes: {len(students)}\")\n",
    "print(f\"  - Intera√ß√µes: {len(interactions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise 1: Estat√≠sticas Gerais das Intera√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Estat√≠sticas Gerais das Intera√ß√µes:\n",
      "\n",
      "  Total de Intera√ß√µes: 4450\n",
      "  Corretas: 1975 (44.4%)\n",
      "  Incorretas: 2475 (55.6%)\n",
      "\n",
      "  Tempo Gasto (segundos):\n",
      "    M√©dia: 157.7s\n",
      "    Mediana: 159.0s\n",
      "    Desvio: 81.9s\n",
      "    Range: [15s, 299s]\n",
      "\n",
      "  Mastery (Dom√≠nio):\n",
      "    M√©dia: 0.549\n",
      "    Mediana: 0.548\n",
      "    Desvio: 0.137\n",
      "\n",
      "  Intera√ß√µes por Estudante:\n",
      "    M√©dia: 44.5\n",
      "    Range: [30, 60]\n"
     ]
    }
   ],
   "source": [
    "def analyze_general_statistics(interactions: List[Dict], students: List) -> Dict[str, Any]:\n",
    "    \"\"\"Calcula estat√≠sticas gerais das intera√ß√µes.\"\"\"\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    total_interactions = len(interactions)\n",
    "    correct_interactions = sum(1 for i in interactions if i['is_correct'])\n",
    "    incorrect_interactions = total_interactions - correct_interactions\n",
    "    \n",
    "    stats['total_interactions'] = total_interactions\n",
    "    stats['correct_interactions'] = correct_interactions\n",
    "    stats['incorrect_interactions'] = incorrect_interactions\n",
    "    stats['accuracy'] = correct_interactions / total_interactions if total_interactions > 0 else 0\n",
    "    \n",
    "    times = [i['time_spent_seconds'] for i in interactions]\n",
    "    stats['time_statistics'] = {\n",
    "        'mean': np.mean(times),\n",
    "        'median': np.median(times),\n",
    "        'std': np.std(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "        'q25': np.percentile(times, 25),\n",
    "        'q75': np.percentile(times, 75)\n",
    "    }\n",
    "    \n",
    "    masteries = [i['mastery_after'] for i in interactions]\n",
    "    stats['mastery_statistics'] = {\n",
    "        'mean': np.mean(masteries),\n",
    "        'median': np.median(masteries),\n",
    "        'std': np.std(masteries),\n",
    "        'min': np.min(masteries),\n",
    "        'max': np.max(masteries),\n",
    "        'q25': np.percentile(masteries, 25),\n",
    "        'q75': np.percentile(masteries, 75)\n",
    "    }\n",
    "    \n",
    "    interactions_per_student = defaultdict(int)\n",
    "    for interaction in interactions:\n",
    "        interactions_per_student[interaction['student_id']] += 1\n",
    "    \n",
    "    student_interaction_counts = list(interactions_per_student.values())\n",
    "    stats['interactions_per_student'] = {\n",
    "        'mean': np.mean(student_interaction_counts),\n",
    "        'median': np.median(student_interaction_counts),\n",
    "        'std': np.std(student_interaction_counts),\n",
    "        'min': np.min(student_interaction_counts),\n",
    "        'max': np.max(student_interaction_counts)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "general_stats = analyze_general_statistics(interactions, students)\n",
    "\n",
    "print(\"\\nüìä Estat√≠sticas Gerais das Intera√ß√µes:\\n\")\n",
    "print(f\"  Total de Intera√ß√µes: {general_stats['total_interactions']}\")\n",
    "print(f\"  Corretas: {general_stats['correct_interactions']} ({general_stats['accuracy']:.1%})\")\n",
    "print(f\"  Incorretas: {general_stats['incorrect_interactions']} ({1-general_stats['accuracy']:.1%})\")\n",
    "print(f\"\\n  Tempo Gasto (segundos):\")\n",
    "print(f\"    M√©dia: {general_stats['time_statistics']['mean']:.1f}s\")\n",
    "print(f\"    Mediana: {general_stats['time_statistics']['median']:.1f}s\")\n",
    "print(f\"    Desvio: {general_stats['time_statistics']['std']:.1f}s\")\n",
    "print(f\"    Range: [{general_stats['time_statistics']['min']:.0f}s, {general_stats['time_statistics']['max']:.0f}s]\")\n",
    "print(f\"\\n  Mastery (Dom√≠nio):\")\n",
    "print(f\"    M√©dia: {general_stats['mastery_statistics']['mean']:.3f}\")\n",
    "print(f\"    Mediana: {general_stats['mastery_statistics']['median']:.3f}\")\n",
    "print(f\"    Desvio: {general_stats['mastery_statistics']['std']:.3f}\")\n",
    "print(f\"\\n  Intera√ß√µes por Estudante:\")\n",
    "print(f\"    M√©dia: {general_stats['interactions_per_student']['mean']:.1f}\")\n",
    "print(f\"    Range: [{general_stats['interactions_per_student']['min']:.0f}, {general_stats['interactions_per_student']['max']:.0f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise 2: Distribui√ß√£o de Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä An√°lise de Distribui√ß√£o de Erros:\n",
      "\n",
      "  Total de Erros: 2475\n",
      "\n",
      "  Distribui√ß√£o por Tipo:\n",
      "    - misconception: 490 (19.8%)\n",
      "    - slip: 513 (20.7%)\n",
      "    - careless: 462 (18.7%)\n",
      "    - misunderstanding: 513 (20.7%)\n",
      "    - incomplete: 497 (20.1%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_error_distribution(interactions: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Analisa distribui√ß√£o de tipos de erro.\"\"\"\n",
    "    \n",
    "    error_distribution = Counter()\n",
    "    error_explanations = defaultdict(list)\n",
    "    \n",
    "    for interaction in interactions:\n",
    "        if interaction['error_type']:\n",
    "            error_distribution[interaction['error_type']] += 1\n",
    "            error_explanations[interaction['error_type']].append(\n",
    "                interaction.get('error_explanation', 'N/A')\n",
    "            )\n",
    "    \n",
    "    total_errors = sum(error_distribution.values())\n",
    "    \n",
    "    error_stats = {}\n",
    "    for error_type, count in error_distribution.items():\n",
    "        error_stats[error_type] = {\n",
    "            'count': count,\n",
    "            'percentage': (count / total_errors * 100) if total_errors > 0 else 0\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'total_errors': total_errors,\n",
    "        'error_distribution': error_stats,\n",
    "        'error_types': list(error_distribution.keys())\n",
    "    }\n",
    "\n",
    "error_analysis = analyze_error_distribution(interactions)\n",
    "\n",
    "print(\"\\nüìä An√°lise de Distribui√ß√£o de Erros:\\n\")\n",
    "print(f\"  Total de Erros: {error_analysis['total_errors']}\")\n",
    "print(f\"\\n  Distribui√ß√£o por Tipo:\")\n",
    "for error_type, stats in error_analysis['error_distribution'].items():\n",
    "    print(f\"    - {error_type}: {stats['count']} ({stats['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise 3: Desempenho por Perfil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Desempenho por Perfil Cognitivo:\n",
      "\n",
      "  balanced:\n",
      "    Estudantes: 30\n",
      "    Acur√°cia: 46.0% (¬±7.5%)\n",
      "    Dom√≠nio: 0.583 (¬±0.049)\n",
      "    Tempo: 158.5s (¬±8.8s)\n",
      "\n",
      "  careful:\n",
      "    Estudantes: 20\n",
      "    Acur√°cia: 40.9% (¬±8.6%)\n",
      "    Dom√≠nio: 0.499 (¬±0.052)\n",
      "    Tempo: 157.0s (¬±11.7s)\n",
      "\n",
      "  intuitive:\n",
      "    Estudantes: 10\n",
      "    Acur√°cia: 40.5% (¬±5.9%)\n",
      "    Dom√≠nio: 0.480 (¬±0.031)\n",
      "    Tempo: 159.7s (¬±6.4s)\n",
      "\n",
      "  logical:\n",
      "    Estudantes: 10\n",
      "    Acur√°cia: 42.8% (¬±6.6%)\n",
      "    Dom√≠nio: 0.533 (¬±0.054)\n",
      "    Tempo: 153.5s (¬±9.4s)\n",
      "\n",
      "  quick_learner:\n",
      "    Estudantes: 20\n",
      "    Acur√°cia: 55.7% (¬±8.5%)\n",
      "    Dom√≠nio: 0.734 (¬±0.062)\n",
      "    Tempo: 158.2s (¬±8.5s)\n",
      "\n",
      "  struggling:\n",
      "    Estudantes: 10\n",
      "    Acur√°cia: 30.8% (¬±7.0%)\n",
      "    Dom√≠nio: 0.293 (¬±0.037)\n",
      "    Tempo: 158.5s (¬±11.3s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_performance_by_profile(interactions: List[Dict], students: List, profiles: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"Analisa desempenho agrupado por perfil cognitivo.\"\"\"\n",
    "    \n",
    "    profile_data = defaultdict(lambda: {\n",
    "        'students': [],\n",
    "        'accuracies': [],\n",
    "        'masteries': [],\n",
    "        'times': []\n",
    "    })\n",
    "    \n",
    "    student_interactions = defaultdict(list)\n",
    "    for interaction in interactions:\n",
    "        student_interactions[interaction['student_id']].append(interaction)\n",
    "    \n",
    "    for student in students:\n",
    "        student_id = student['id']\n",
    "        profile_id = student['profile_id']\n",
    "        student_ints = student_interactions.get(student_id, [])\n",
    "        \n",
    "        if not student_ints:\n",
    "            continue\n",
    "        \n",
    "        accuracy = sum(1 for i in student_ints if i['is_correct']) / len(student_ints)\n",
    "        avg_mastery = np.mean([i['mastery_after'] for i in student_ints])\n",
    "        avg_time = np.mean([i['time_spent_seconds'] for i in student_ints])\n",
    "        \n",
    "        profile_data[profile_id]['students'].append(student_id)\n",
    "        profile_data[profile_id]['accuracies'].append(accuracy)\n",
    "        profile_data[profile_id]['masteries'].append(avg_mastery)\n",
    "        profile_data[profile_id]['times'].append(avg_time)\n",
    "    \n",
    "    profile_stats = {}\n",
    "    for profile_id, data in profile_data.items():\n",
    "        if data['accuracies']:\n",
    "            profile_stats[profile_id] = {\n",
    "                'num_students': len(data['students']),\n",
    "                'accuracy': {\n",
    "                    'mean': np.mean(data['accuracies']),\n",
    "                    'std': np.std(data['accuracies']),\n",
    "                    'min': np.min(data['accuracies']),\n",
    "                    'max': np.max(data['accuracies'])\n",
    "                },\n",
    "                'mastery': {\n",
    "                    'mean': np.mean(data['masteries']),\n",
    "                    'std': np.std(data['masteries'])\n",
    "                },\n",
    "                'time': {\n",
    "                    'mean': np.mean(data['times']),\n",
    "                    'std': np.std(data['times'])\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    return profile_stats\n",
    "\n",
    "profile_performance = analyze_performance_by_profile(interactions, students, profiles)\n",
    "\n",
    "print(\"\\nüìä Desempenho por Perfil Cognitivo:\\n\")\n",
    "for profile_id, stats in sorted(profile_performance.items()):\n",
    "    print(f\"  {profile_id}:\")\n",
    "    print(f\"    Estudantes: {stats['num_students']}\")\n",
    "    print(f\"    Acur√°cia: {stats['accuracy']['mean']:.1%} (¬±{stats['accuracy']['std']:.1%})\")\n",
    "    print(f\"    Dom√≠nio: {stats['mastery']['mean']:.3f} (¬±{stats['mastery']['std']:.3f})\")\n",
    "    print(f\"    Tempo: {stats['time']['mean']:.1f}s (¬±{stats['time']['std']:.1f}s)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise 4: Padr√£o de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä An√°lise de Padr√µes de Aprendizado:\n",
      "\n",
      "  Estudantes Analisados: 100\n",
      "\n",
      "  Tend√™ncias:\n",
      "    Crescimento Monot√¥nico: 81 (81.0%)\n",
      "    Decrescimento: 19 (19.0%)\n",
      "    Flutuante: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_learning_patterns(interactions: List[Dict], students: List) -> Dict[str, Any]:\n",
    "    \"\"\"Analisa padr√µes de aprendizado ao longo do tempo.\"\"\"\n",
    "    \n",
    "    student_interactions = defaultdict(list)\n",
    "    for interaction in interactions:\n",
    "        student_interactions[interaction['student_id']].append(interaction)\n",
    "    \n",
    "    monotonic_increasing = 0\n",
    "    monotonic_decreasing = 0\n",
    "    fluctuating = 0\n",
    "    \n",
    "    learning_curves = {}\n",
    "    \n",
    "    for student_id, student_ints in student_interactions.items():\n",
    "        if len(student_ints) < 2:\n",
    "            continue\n",
    "        \n",
    "        sorted_ints = sorted(student_ints, key=lambda x: x['timestamp'])\n",
    "        masteries = [i['mastery_after'] for i in sorted_ints]\n",
    "        \n",
    "        learning_curves[student_id] = masteries\n",
    "        \n",
    "        first_half_mean = np.mean(masteries[:len(masteries)//2])\n",
    "        second_half_mean = np.mean(masteries[len(masteries)//2:])\n",
    "        \n",
    "        if second_half_mean > first_half_mean:\n",
    "            monotonic_increasing += 1\n",
    "        elif second_half_mean < first_half_mean:\n",
    "            monotonic_decreasing += 1\n",
    "        else:\n",
    "            fluctuating += 1\n",
    "    \n",
    "    total_students = len(learning_curves)\n",
    "    \n",
    "    return {\n",
    "        'total_students_analyzed': total_students,\n",
    "        'monotonic_increasing': {\n",
    "            'count': monotonic_increasing,\n",
    "            'percentage': (monotonic_increasing / total_students * 100) if total_students > 0 else 0\n",
    "        },\n",
    "        'monotonic_decreasing': {\n",
    "            'count': monotonic_decreasing,\n",
    "            'percentage': (monotonic_decreasing / total_students * 100) if total_students > 0 else 0\n",
    "        },\n",
    "        'fluctuating': {\n",
    "            'count': fluctuating,\n",
    "            'percentage': (fluctuating / total_students * 100) if total_students > 0 else 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "learning_patterns = analyze_learning_patterns(interactions, students)\n",
    "\n",
    "print(\"\\nüìä An√°lise de Padr√µes de Aprendizado:\\n\")\n",
    "print(f\"  Estudantes Analisados: {learning_patterns['total_students_analyzed']}\")\n",
    "print(f\"\\n  Tend√™ncias:\")\n",
    "print(f\"    Crescimento Monot√¥nico: {learning_patterns['monotonic_increasing']['count']} ({learning_patterns['monotonic_increasing']['percentage']:.1f}%)\")\n",
    "print(f\"    Decrescimento: {learning_patterns['monotonic_decreasing']['count']} ({learning_patterns['monotonic_decreasing']['percentage']:.1f}%)\")\n",
    "print(f\"    Flutuante: {learning_patterns['fluctuating']['count']} ({learning_patterns['fluctuating']['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise 5: Correla√ß√£o entre Par√¢metros e Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Correla√ß√£o entre Par√¢metros e Desempenho:\n",
      "\n",
      "  Par√¢metro | Correla√ß√£o com Acur√°cia | Correla√ß√£o com Dom√≠nio\n",
      "  ------------------------------------------------------------\n",
      "  mastery_init         |  0.730 |  0.956\n",
      "  tech_familiarity     |  0.617 |  0.857\n",
      "  learn_rate           |  0.585 |  0.785\n",
      "  logic_skill          |  0.458 |  0.633\n",
      "  guess                | -0.208 | -0.367\n",
      "  reading_skill        |  0.196 |  0.258\n",
      "  slip                 | -0.025 | -0.119\n",
      "\n",
      "  Top 3 Fatores Mais Importantes:\n",
      "    1. mastery_init\n",
      "    2. tech_familiarity\n",
      "    3. learn_rate\n"
     ]
    }
   ],
   "source": [
    "def analyze_parameter_correlations(interactions: List[Dict], students: List) -> Dict[str, Any]:\n",
    "    \"\"\"Analisa correla√ß√£o entre par√¢metros dos estudantes e seu desempenho.\"\"\"\n",
    "    \n",
    "    student_interactions = defaultdict(list)\n",
    "    for interaction in interactions:\n",
    "        student_interactions[interaction['student_id']].append(interaction)\n",
    "    \n",
    "    data = []\n",
    "    for student in students:\n",
    "        student_id = student['id']\n",
    "        student_ints = student_interactions.get(student_id, [])\n",
    "        if not student_ints:\n",
    "            continue\n",
    "        \n",
    "        accuracy = sum(1 for i in student_ints if i['is_correct']) / len(student_ints)\n",
    "        avg_mastery = np.mean([i['mastery_after'] for i in student_ints])\n",
    "        \n",
    "        data.append({\n",
    "            'student_id': student_id,\n",
    "            'accuracy': accuracy,\n",
    "            'avg_mastery': avg_mastery,\n",
    "            'learn_rate': student.get('learn_rate', 0),\n",
    "            'logic_skill': student.get('logic_skill', 0),\n",
    "            'reading_skill': student.get('reading_skill', 0),\n",
    "            'tech_familiarity': student.get('tech_familiarity', 0),\n",
    "            'mastery_init': student.get('mastery_init_level', 0),\n",
    "            'slip': student.get('slip', 0),\n",
    "            'guess': student.get('guess', 0)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    correlations = {}\n",
    "    for param in ['learn_rate', 'logic_skill', 'reading_skill',\n",
    "                  'tech_familiarity', 'mastery_init', 'slip', 'guess']:\n",
    "        if param in df.columns:\n",
    "            corr_with_accuracy = df[param].corr(df['accuracy'])\n",
    "            corr_with_mastery = df[param].corr(df['avg_mastery'])\n",
    "            correlations[param] = {\n",
    "                'correlation_with_accuracy': round(corr_with_accuracy, 3),\n",
    "                'correlation_with_mastery': round(corr_with_mastery, 3)\n",
    "            }\n",
    "    \n",
    "    sorted_by_accuracy = sorted(\n",
    "        correlations.items(),\n",
    "        key=lambda x: abs(x[1]['correlation_with_accuracy']),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'correlations': dict(sorted_by_accuracy),\n",
    "        'top_3_factors': [f[0] for f in sorted_by_accuracy[:3]]\n",
    "    }\n",
    "\n",
    "correlations = analyze_parameter_correlations(interactions, students)\n",
    "\n",
    "print(\"\\nüìä Correla√ß√£o entre Par√¢metros e Desempenho:\\n\")\n",
    "print(\"  Par√¢metro | Correla√ß√£o com Acur√°cia | Correla√ß√£o com Dom√≠nio\")\n",
    "print(\"  \" + \"-\" * 60)\n",
    "for param, corrs in list(correlations['correlations'].items())[:10]:\n",
    "    acc_corr = corrs['correlation_with_accuracy']\n",
    "    mas_corr = corrs['correlation_with_mastery']\n",
    "    print(f\"  {param:20s} | {acc_corr:>6.3f} | {mas_corr:>6.3f}\")\n",
    "\n",
    "print(f\"\\n  Top 3 Fatores Mais Importantes:\")\n",
    "for i, factor in enumerate(correlations['top_3_factors'], 1):\n",
    "    print(f\"    {i}. {factor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compila√ß√£o do Relat√≥rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Relat√≥rio salvo em: data/output/analysis_report.json\n"
     ]
    }
   ],
   "source": [
    "def convert_to_json_serializable(obj):\n",
    "    \"\"\"Converte tipos NumPy para tipos nativos Python.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_to_json_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_json_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "final_report = {\n",
    "    \"metadata\": {\n",
    "        \"description\": \"Relat√≥rio de an√°lise estat√≠stica das intera√ß√µes SINKT\",\n",
    "        \"version\": \"2.0.0\",\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"total_profiles\": len(profiles),\n",
    "        \"total_students\": len(students),\n",
    "        \"total_interactions\": len(interactions)\n",
    "    },\n",
    "    \"general_statistics\": general_stats,\n",
    "    \"error_analysis\": error_analysis,\n",
    "    \"profile_performance\": profile_performance,\n",
    "    \"learning_patterns\": learning_patterns,\n",
    "    \"parameter_correlations\": correlations,\n",
    "    \"summary\": {\n",
    "        \"data_quality\": \"ALTA\" if general_stats['accuracy'] > 0.3 and general_stats['accuracy'] < 0.9 else \"M√âDIA\",\n",
    "        \"learning_pattern_quality\": \"EXCELENTE\" if learning_patterns['monotonic_increasing']['percentage'] > 70 else \"BOA\",\n",
    "        \"profile_differentiation\": \"CLARA\" if len(profile_performance) > 1 else \"FRACA\"\n",
    "    }\n",
    "}\n",
    "\n",
    "final_report = convert_to_json_serializable(final_report)\n",
    "\n",
    "report_file = 'data/output/analysis_report.json'\n",
    "with open(report_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Relat√≥rio salvo em: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ AN√ÅLISE ESTAT√çSTICA CONCLU√çDA COM SUCESSO!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Arquivo gerado:\n",
      "  - data/output/analysis_report.json\n",
      "\n",
      "üìä Resumo Executivo:\n",
      "  - Qualidade dos Dados: ALTA\n",
      "  - Qualidade do Padr√£o de Aprendizado: EXCELENTE\n",
      "  - Diferencia√ß√£o entre Perfis: CLARA\n",
      "\n",
      "‚úÖ Pr√≥ximo passo: Consulte 'docs/03_respostas_obrigatorias.md' para respostas √†s perguntas\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ AN√ÅLISE ESTAT√çSTICA CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Arquivo gerado:\")\n",
    "print(f\"  - {report_file}\")\n",
    "print(f\"\\nüìä Resumo Executivo:\")\n",
    "print(f\"  - Qualidade dos Dados: {final_report['summary']['data_quality']}\")\n",
    "print(f\"  - Qualidade do Padr√£o de Aprendizado: {final_report['summary']['learning_pattern_quality']}\")\n",
    "print(f\"  - Diferencia√ß√£o entre Perfis: {final_report['summary']['profile_differentiation']}\")\n",
    "print(f\"\\n‚úÖ Pr√≥ximo passo: Consulte 'docs/03_respostas_obrigatorias.md' para respostas √†s perguntas\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
