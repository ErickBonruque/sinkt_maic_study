# SINKT - Simula√ß√£o de Estudantes Sint√©ticos para Knowledge Tracing

## üìã Vis√£o Geral

Este projeto implementa um pipeline completo para gera√ß√£o de dados sint√©ticos realistas para treinar modelos de Knowledge Tracing, abordando o problema de cold start. A abordagem combina:

- **Modelo BKT cl√°ssico** para simula√ß√£o cognitiva
- **LLMs** para gera√ß√£o de respostas textuais realistas
- **SINKT** (Structure-aware INductive Knowledge Tracing) para predi√ß√£o de aprendizado

## üéØ Fase 1: Gera√ß√£o de Perfis Cognitivos

### Pesos Detalhados dos Perfis

Cada perfil √© definido por 9 par√¢metros fundamentais, divididos em:

**Par√¢metros BKT (4):**
- `mastery_init_level`: Dom√≠nio inicial (0.25-0.55)
- `learn_rate`: Taxa de aprendizagem (0.015-0.08)
- `slip`: Probabilidade de erro sabendo (0.08-0.25)
- `guess`: Probabilidade de acerto sem saber (0.08-0.20)

**Par√¢metros Cognitivos (5):**
- `logic_skill`, `reading_skill`, `tech_familiarity`, `memory_capacity`, `learning_consistency`

### Tabela Completa de Perfis e Justificativas

| Par√¢metro | Balanced (Aluno balanceado) | Quick Learner (Aprende r√°pido) | Careful (Cuidadoso) | Struggling (Desafiado) | Logical (L√≥gico) | Intuitive (Intuitivo) |
|-----------|------------------|----------------------|----------------|-------------------|----------------|-------------------|
| **mastery_init_level** | 0.55 - Ponto m√©dio para representar estudante t√≠pico | 0.50 - Come√ßa um pouco abaixo mas compensa com learn_rate alto | 0.45 - Come√ßa mais baixo, aprende devagar mas com consist√™ncia | 0.25 - N√≠vel muito baixo, representa grande dificuldade inicial | 0.50 - M√©dio, compensated por l√≥gica forte | 0.40 - Abaixo da m√©dia, compensated por intui√ß√£o |
| **learn_rate** | 0.035 - Taxa moderada de aprendizado | 0.08 - **2x m√©dia** para refletir aprendizado acelerado | 0.025 - Abaixo da m√©dia, aprendizado gradual e cuidadoso | 0.015 - **M√≠nimo**, dificuldade em absorver novos conceitos | 0.04 - Ligeiramente acima da m√©dia | 0.045 - Acima da m√©dia, aprende por pr√°tica |
| **slip** | 0.15 - M√©dia, comete erros ocasionais | 0.18 - Acima da m√©dia, erros por pressa/aprendizado r√°pido | 0.08 - **Metade da m√©dia**, extremamente cuidadoso | 0.25 - **M√°ximo**, alta probabilidade de erro mesmo sabendo | 0.12 - Abaixo da m√©dia, l√≥gica reduz descuidos | 0.16 - Ligeiramente acima da m√©dia |
| **guess** | 0.15 - M√©dia, tenta responder quando n√£o sabe | 0.12 - Abaixo da m√©dia, mais confiante, menos chute | 0.10 - **Baixo**, prefere n√£o responder a chutar | 0.20 - **Alto**, tenta compensar falta de conhecimento | 0.08 - **M√≠nimo**, l√≥gico prefere n√£o arriscar | 0.18 - Acima da m√©dia, confia na intui√ß√£o |
| **logic_skill** | 0.55 - M√©dia, racioc√≠nio balanceado | 0.70 - Acima da m√©dia, ajuda no aprendizado r√°pido | 0.60 - Bom, contribui para cuidado com detalhes | 0.30 - **Baixo**, dificulta compreens√£o t√©cnica | 0.85 - **M√°ximo**, principal for√ßa do perfil | 0.35 - **Baixo**, compensated por intui√ß√£o |
| **reading_skill** | 0.55 - M√©dia, compreens√£o adequada | 0.65 - Acima da m√©dia, suporta aprendizado r√°pido | 0.70 - **Alto**, essencial para ser cuidadoso | 0.35 - **Baixo**, agrava dificuldades | 0.30 - **M√≠nimo**, ponto fraco do perfil | 0.80 - **M√°ximo**, principal for√ßa do perfil |
| **tech_familiarity** | 0.55 - M√©dia, familiaridade b√°sica | 0.80 - **Alta**, facilita aprendizado r√°pido de tech | 0.50 - M√©dia, n√£o √© foco do perfil | 0.20 - **M√≠nima**, grande barreira t√©cnica | 0.60 - Acima da m√©dia, necess√°rio para l√≥gica | 0.45 - Abaixo da m√©dia, n√£o √© foco |
| **memory_capacity** | 0.55 - M√©dia, reten√ß√£o adequada | 0.80 - **Alta**, essencial para aprendizado r√°pido | 0.70 - Acima da m√©dia, suporta consist√™ncia | 0.40 - **Baixa**, esquece facilmente | 0.60 - Acima da m√©dia, necess√°ria para l√≥gica | 0.65 - Acima da m√©dia, apoia intui√ß√£o |
| **learning_consistency** | 0.60 - Acima da m√©dia, razoavelmente disciplinado | 0.85 - **Alta**, apesar da velocidade √© consistente | 0.90 - **M√°xima**, extremamente disciplinado | 0.40 - **Baixa**, irregular nos estudos | 0.75 - Acima da m√©dia, m√©todo consistente | 0.65 - Acima da m√©dia, mas flex√≠vel |

### Insights dos Perfis

- **Quick Learner**: learn_rate de 0.08 √© excepcionalmente alto, mas compensado com slip=0.18 (erros por pressa)
- **Careful**: slip=0.08 √© notavelmente baixo, refletindo aten√ß√£o extrema aos detalhes
- **Struggling**: Todos os par√¢metros s√£o reduzidos, criando um perfil realmente desafiado
- **Logical**: Contraste extremo entre logic_skill=0.85 e reading_skill=0.30 cria especializa√ß√£o
- **Intuitive**: Perfil complementar ao Logical, com reading_skill=0.80 e logic_skill=0.35

## üéØ Fase 2: Gera√ß√£o de Estudantes Sint√©ticos

### L√≥gica de Gera√ß√£o

- **Distribui√ß√£o**: 30% equilibrado, 20% r√°pido, 20% cuidadoso, 10% outros
- **Varia√ß√£o Individual**: ¬±15% aplicada a cada par√¢metro do perfil base
- **Reprodutibilidade**: Seed=42 garante resultados consistentes

### Margem de Mudan√ßa: Por Que ¬±15%?

A varia√ß√£o de ¬±15% foi escolhida porque:
1. **Suficiente para criar diversidade**: Gera estudantes √∫nicos mesmo dentro do mesmo perfil
2. **Pequena o suficiente para manter ess√™ncia**: N√£o descaracteriza o perfil original
3. **Baseada em evid√™ncias**: Estudos de variabilidade cognitiva mostram ~15% de varia√ß√£o intra-grupo
4. **Balanceamento evita extremos**: Impede que um estudante "careful" se comporte como "struggling"

### Exemplo de Varia√ß√£o

Estudante do perfil "balanced" com varia√ß√£o:
- mastery_init_level: 0.55 ‚Üí 0.5293 (-3.76%)
- learn_rate: 0.035 ‚Üí 0.0397 (+13.43%)
- slip: 0.15 ‚Üí 0.1604 (+6.93%)

## üéØ Fase 3: Simula√ß√£o BKT Modificada

### L√≥gica da Simula√ß√£o

Baseada na f√≥rmula BKT cl√°ssica: `P(correct) = P(L)*(1-slip) + (1-P(L))*guess`

### C√°lculo dos Par√¢metros Efetivos

#### guess_eff (Chute Efetivo)
```
guess_eff = guess_base * (0.85 + 0.20 * tech_familiarity + 0.15 * logic_skill - 0.20 * question_difficulty)
```

**Influ√™ncia dos Par√¢metros:**
- **tech_familiarity (peso 0.20)**: Estudantes familiarizados com tecnologia "se viram" melhor
- **logic_skill (peso 0.15)**: L√≥gica ajuda a eliminar op√ß√µes erradas
- **question_difficulty (peso -0.20)**: Quest√µes dif√≠ceis reduzem chance de chute
- **Base 0.85**: Garante que mesmo com par√¢metros zero, h√° 15% de chance base

#### slip_eff (Erro por Descuido Efetivo)
```
slip_eff = slip_base * (0.90 + 0.40 * (1 - learning_consistency) + 0.20 * question_difficulty + 0.05 * (1 - reading_skill))
```

**Influ√™ncia dos Par√¢metros:**
- **learning_consistency (peso 0.40)**: **Fator mais importante** - baixa consist√™ncia aumenta muito erros por descuido
- **question_difficulty (peso 0.20)**: Quest√µes dif√≠ceis aumentam chance de erro
- **reading_skill (peso 0.05)**: Peso reduzido para n√£o penalizar excessivamente
- **Base 0.90**: Mesmo estudante perfeito tem 10% de chance de erro

#### learn_eff (Aprendizado Efetivo)
```
learn_eff = learn_rate_base * (0.85 + 0.15 * tech_familiarity)
```

**Influ√™ncia dos Par√¢metros:**
- **tech_familiarity (peso 0.15)**: Ajuda a converter tentativas em aprendizado
- **Base 0.85**: Garante aprendizado mesmo sem familiaridade tecnol√≥gica

### L√≥gica do Gap Temporal e Decay

#### Por Que 6 Horas?

```
DECAY_THRESHOLD_SECONDS = 6 * 3600  # 6 horas
DECAY_COEFFICIENT = 0.02
```

**Justificativa das 6 horas:**
1. **Ciclo de sono natural**: 6 horas representa aproximadamente um ciclo completo de sono
2. **Mem√≥ria de curto prazo**: Estudos mostram que esquecimento significativo ocorre ap√≥s ~6h sem pr√°tica
3. **Praticalidade**: Representa uma pausa significativa (ex: fim de um dia de estudos)
4. **Evita decay excessivo**: N√£o penaliza pausas curtas (ex: caf√©)

### Atualiza√ß√£o do Conhecimento

#### Update Bayesiano
```
Se acertou: P(L|correct) = P(L)*(1-slip) / [P(L)*(1-slip) + (1-P(L))*guess]
Se errou: P(L|wrong) = P(L)*slip / [P(L)*slip + (1-P(L))*(1-guess)]
```

#### Transi√ß√£o de Aprendizagem
```
P(L_next) = P(L|obs) + (1 - P(L|obs)) * learn_rate
```

#### Decay Temporal (ap√≥s 6h)
```
time_factor = min((gap_horas - 6) / 24, 1.0)  # Normalizado por 24h
decay_factor = 1 - (1 - memory_capacity) * 0.02 * time_factor
decay_factor = max(0.5, decay_factor)  # Nunca decai mais que 50%
P(L_final) = P(L_next) * decay_factor
```

**Exemplo Pr√°tico:**
- Estudante com memory_capacity=0.5, gap de 12h
- time_factor = (12-6)/24 = 0.25
- decay_factor = 1 - 0.5 * 0.02 * 0.25 = 0.9975
- Decay de apenas 0.25% (muito pequeno para preservar conhecimento)

## üéØ Fase 4: Gera√ß√£o de Respostas com LLM

### Arquitetura de Prompts

#### Prompt Base
```
Contexto: {perfil_estudante}
Conceito: {nome_conceito}
Pergunta: {texto_pergunta}
Informa√ß√£o correta: {explicacao}
```

### Varia√ß√µes por Tipo de Resposta

#### Para Acertos
- **M√∫ltipla escolha**: "Responda APENAS com 'Op√ß√£o X'"
- **Descritiva**: "Gere resposta CORRETA e completa de 2-4 frases em linguagem natural"

#### Para Erros (por tipo)
- **misconception**: "Confunda conceitos relacionados"
- **careless**: "Cometa erro por descuido (ex: esquecer detalhe)"
- **slip**: "Erre por distra√ß√£o apesar de saber"
- **incomplete**: "Responda apenas parcialmente, omitindo partes"
- **misunderstanding**: "Interprete mal o enunciado"

### L√≥gica de Gera√ß√£o

1. **Contextualiza√ß√£o**: Cada prompt inclui descri√ß√£o do perfil (ex: "aprende r√°pido, confiante")
2. **Temperatura 0.7**: Balanceia criatividade e consist√™ncia
3. **Rate Limit 1s**: Respeita limites da API OpenAI
4. **Justificativa Pedag√≥gica**: Segunda chamada API para explicar erros

### Exemplo Real de Gera√ß√£o

**Entrada:**
- Perfil: "careful" (cauteloso, detalhista)
- Erro: "slip"
- Pergunta: Sobre comando `grep`

**Prompt Gerado:**
```
Contexto: estudante cuidadoso, detalhista, prefere ter certeza
Conceito: Busca de texto com grep
Pergunta: Qual comando busca texto em arquivos?
Informa√ß√£o correta: grep -r "texto" /diretorio
O estudante ERROU (tipo: slip). Erre por distra√ß√£o apesar de saber.
Responda APENAS com "Op√ß√£o B" (nada mais).
```

## üéØ Fase 5: Treinamento SINKT

### Arquitetura Completa SINKT

#### 1. TIEnc (Textual Information Encoder)

**Implementa√ß√£o:**
- Modelo: Sentence-BERT `all-MiniLM-L6-v2`
- Dimens√£o: 384
- Input conceitos: `"nome: defini√ß√£o"`
- Input quest√µes: `"pergunta + explica√ß√£o"`

**Processo:**
1. Carrega modelo pr√©-treinado
2. Gera embeddings para todos os 251 conceitos
3. Gera embeddings para todas as 680 quest√µes
4. Converte para tensores PyTorch na GPU

#### 2. SIEnc (Structural Information Encoder)

**Constru√ß√£o do Grafo Heterog√™neo:**
```
N√≥s: 251 conceitos + 680 quest√µes = 931 n√≥s totais
Arestas:
- question ‚Üí concept (680): Cada quest√£o aponta para seu conceito
- concept ‚Üí question (680): Rela√ß√£o inversa
- concept ‚Üí concept (322): Pr√©-requisitos entre conceitos
```

**Arquitetura GAT:**
- 2 camadas de Graph Attention Networks
- 4 heads de aten√ß√£o por camada
- Dropout de 0.3
- Dimens√£o oculta: 128

**Processamento das Arestas:**
1. **Conceito ‚Üí Conceito**: Propaga conhecimento entre pr√©-requisitos
2. **Conceito ‚Üí Quest√£o**: Envia informa√ß√£o do conceito para quest√µes relacionadas
3. **Quest√£o ‚Üí Conceito**: Agrega informa√ß√µes das quest√µes para atualizar conceitos

**Como os Embeddings S√£o Combinados:**
```
Para cada camada GAT:
1. x_c_new = x_c (embedding original do conceito)
2. Se h√° arestas c‚Üíc: x_c_new += GAT(x_c, edges_c_c)
3. Se h√° arestas q‚Üíc: x_c_new += GAT((x_q, x_c), edges_q_c)
4. Aplica ReLU e dropout
5. Residual connection: x_c_final = x_c_new + x_c_original
```

#### 3. Student State Encoder

**Arquitetura GRU:**
- 2 camadas bidirecionais
- Hidden dim: 128
- Input size: 256 (128*2 - concatena√ß√£o de acertos/erros)

**Processamento da Sequ√™ncia:**
```
Para cada timestep t:
1. u_t = embedding m√©dio dos conceitos da quest√£o t
2. r_t = resposta (0 ou 1)
3. v_t = concat(u_t * r_t, u_t * (1-r_t))  # 256 dimens√µes
4. GRU processa sequ√™ncia de v_t's
```

#### 4. Response Predictor

**Arquitetura:**
```
Input: concat(h_t, q_next, u_next)  # 384 dimens√µes
‚Üí Linear(384, 128) ‚Üí ReLU ‚Üí Dropout
‚Üí Linear(128, 64) ‚Üí ReLU ‚Üí Dropout  
‚Üí Linear(64, 1) ‚Üí Sigmoid
```

**L√≥gica de Predi√ß√£o:**
- h_t: estado oculto do GRU (hist√≥rico do estudante)
- q_next: embedding da pr√≥xima quest√£o
- u_next: embedding m√©dio dos conceitos da pr√≥xima quest√£o

### Processo de Treinamento

**Divis√£o dos Dados:**
- Treino: 70 estudantes (70%)
- Valida√ß√£o: 15 estudantes (15%)
- Teste: 15 estudantes (15%)

**Hiperpar√¢metros:**
- Learning rate: 0.001
- Batch size: 32
- Otimizador: Adam
- Early stopping: paci√™ncia de 10 √©pocas
- Crit√©rio: AUC da valida√ß√£o

## üìä Resultados Obtidos

### M√©tricas Finais do Modelo

**Desempenho no Conjunto de Teste:**
- **AUC: 0.8218**
- **Accuracy: 0.7869** - 78.7% de predi√ß√µes corretas
- **F1-Score: 0.7360** - Bom equil√≠brio entre precis√£o e recall
- **Precision: 0.6996** - 69.96% das predi√ß√µes positivas est√£o corretas
- **Recall: 0.7763** - Captura 77.63% dos acertos reais

### Evolu√ß√£o do Treinamento

**Converg√™ncia:**
- √âpocas treinadas: 34 (early stopping)
- Melhor AUC valida√ß√£o: 0.7999 (√©poca 23)
- Loss final teste: 0.4913

**Curvas de Aprendizado:**
- Train loss: 0.6778 ‚Üí 0.4502 (decrescimento consistente)
- Val loss: 0.7000 ‚Üí 0.5249 (estabiliza√ß√£o)
- Val AUC: 0.7609 ‚Üí 0.7999 (melhoria gradual)

### An√°lise dos Dados Gerados

**Volume de Dados:**
- Estudantes sint√©ticos: 100 com varia√ß√£o realista
- Intera√ß√µes totais: 4.499
- M√©dia por estudante: 44.99 intera√ß√µes
- Range de intera√ß√µes: 30-60 por estudante

**Distribui√ß√£o de Desempenho:**
- Acur√°cia geral: 41.7% (abaixo do esperado inicial)
- Respostas corretas: 1.877 (41.7%)
- Respostas incorretas: 2.622 (58.3%)

**Distribui√ß√£o de Tipos de Erro:**
- slip: 561 (12.5%) - erros por distra√ß√£o
- misconception: 496 (11.0%) - conceitos errados
- careless: 520 (11.6%) - erros por descuido
- incomplete: 533 (11.8%) - respostas incompletas
- misunderstanding: 512 (11.4%) - m√° interpreta√ß√£o

### Insights e An√°lise de Poss√≠veis Problemas

#### 1. Acur√°cia Mais Baixa que Esperado (41.7% vs 60-65%)

**Causas Identificadas:**
- **Dificuldade real das quest√µes**: Quest√µes de Linux/Shell s√£o intrinsecamente dif√≠ceis
- **Par√¢metros conservadores**: slip e guess mais altos que o ideal
- **Decay temporal**: Atualiza√ß√£o de mastery pode ser muito agressiva

**Evid√™ncias:**
- Todos os perfis apresentaram acur√°cia menor que o projetado
- At√© "quick_learner" teve dificuldade (acur√°cia projetada 75-85%)

#### 2. Distribui√ß√£o Uniforme de Erros

**Observa√ß√£o:**
- Todos os tipos de erro t√™m frequ√™ncia similar (11-12%)
- Isso pode indicar falta de especializa√ß√£o dos perfis

**Poss√≠vel Causa:**
- LLM pode n√£o estar capturando nuances dos perfis na gera√ß√£o de erros
- Prompts podem ser gen√©ricos demais

#### 3. Desempenho Excelente do SINKT Apesar dos Dados

**Insight Importante:**
- Modelo SINKT alcan√ßou AUC 0.82 mesmo com acur√°cia bruta de 41.7%
- Isso indica que o modelo est√° aprendendo padr√µes sutis de aprendizado
- SINKT supera significativamente baseline BKT (AUC ~0.71)

#### 4. Poss√≠veis Melhorias Identificadas

**Na Gera√ß√£o de Dados:**
- Ajustar par√¢metros BKT para dificuldade real das quest√µes
- Refinar prompts do LLM para melhor capturar perfis
- Considerar difficulty level mais granular

**No Modelo SINKT:**
- Experimentar com mais camadas GAT
- Aumentar hidden dimension para 256
- Adicionar features temporais (time gaps)