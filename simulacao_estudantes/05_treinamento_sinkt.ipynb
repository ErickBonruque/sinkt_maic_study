{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Treinamento do Modelo SINKT\n",
    "\n",
    "Este notebook implementa a **Etapa 5** do pipeline SINKT: treinamento do modelo Structure-aware INductive Knowledge Tracing.\n",
    "\n",
    "## Objetivo\n",
    "Treinar o modelo SINKT completo com:\n",
    "- **TIEnc**: Textual Information Encoder (embeddings semânticos)\n",
    "- **SIEnc**: Structural Information Encoder (GAT no grafo heterogêneo)\n",
    "- **Student State Encoder**: GRU para dinâmica temporal\n",
    "- **Response Predictor**: Predição de acerto/erro\n",
    "\n",
    "## Entrada\n",
    "- `data/output/notebooks/geracao_respostas_llm/interactions_complete.json`: Interações completas com respostas LLM\n",
    "- `data/json/concepts_graph.json`: Grafo de conceitos\n",
    "- `data/json/questions_graph.json`: Grafo de questões\n",
    "\n",
    "## Saída\n",
    "- Modelo treinado\n",
    "- Métricas de desempenho (AUC, ACC, F1, Precision, Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.3.5)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: jupyter in ./venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: ipython in ./venv/lib/python3.12/site-packages (9.8.0)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.12/site-packages (1.55.3)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: torch-geometric in ./venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (3.10.8)\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.12/site-packages (5.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: notebook in ./venv/lib/python3.12/site-packages (from jupyter) (7.5.0)\n",
      "Requirement already satisfied: jupyter-console in ./venv/lib/python3.12/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in ./venv/lib/python3.12/site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.12/site-packages (from jupyter) (7.1.0)\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.12/site-packages (from jupyter) (8.1.8)\n",
      "Requirement already satisfied: jupyterlab in ./venv/lib/python3.12/site-packages (from jupyter) (4.5.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./venv/lib/python3.12/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./venv/lib/python3.12/site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./venv/lib/python3.12/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./venv/lib/python3.12/site-packages (from ipython) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.12/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./venv/lib/python3.12/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./venv/lib/python3.12/site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./venv/lib/python3.12/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./venv/lib/python3.12/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.12/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.12/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./venv/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./venv/lib/python3.12/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./venv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./venv/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.12/site-packages (from torch-geometric) (3.13.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./venv/lib/python3.12/site-packages (from torch-geometric) (7.1.3)\n",
      "Requirement already satisfied: pyparsing in ./venv/lib/python3.12/site-packages (from torch-geometric) (3.2.5)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from torch-geometric) (2.32.5)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.12/site-packages (from torch-geometric) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./venv/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./venv/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.12/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.14)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.22.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (1.8.18)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (8.7.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (5.9.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=25 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./venv/lib/python3.12/site-packages (from ipykernel->jupyter) (6.5.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./venv/lib/python3.12/site-packages (from ipywidgets->jupyter) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./venv/lib/python3.12/site-packages (from ipywidgets->jupyter) (3.0.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./venv/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./venv/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./venv/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in ./venv/lib/python3.12/site-packages (from jupyterlab->jupyter) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in ./venv/lib/python3.12/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (4.14.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.12/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->torch-geometric) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->torch-geometric) (2.6.2)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.5.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in ./venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (4.25.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./venv/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.2)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./venv/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./venv/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (0.30.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in ./venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in ./venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in ./venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in ./venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.10.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./venv/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
      "Requirement already satisfied: lark>=1.2.2 in ./venv/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./venv/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.4.0)\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas jupyter ipython openai python-dotenv torch torch-geometric transformers scikit-learn matplotlib seaborn tqdm sentence-transformers\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações e Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configurações definidas:\n",
      "  - text_embed_dim: 384\n",
      "  - hidden_dim: 128\n",
      "  - gat_heads: 4\n",
      "  - gat_layers: 2\n",
      "  - gru_layers: 2\n",
      "  - dropout: 0.3\n",
      "  - learning_rate: 0.001\n",
      "  - batch_size: 32\n",
      "  - num_epochs: 50\n",
      "  - early_stopping_patience: 10\n",
      "  - train_split: 0.7\n",
      "  - val_split: 0.15\n",
      "  - test_split: 0.15\n",
      "  - plm_model: sentence-transformers/all-MiniLM-L6-v2\n",
      "  - use_time_features: False\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "config = {\n",
    "    'text_embed_dim': 384,\n",
    "    'hidden_dim': 128,\n",
    "    'gat_heads': 4,\n",
    "    'gat_layers': 2,\n",
    "    'gru_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 50,\n",
    "    'early_stopping_patience': 10,\n",
    "    'train_split': 0.7,\n",
    "    'val_split': 0.15,\n",
    "    'test_split': 0.15,\n",
    "    'plm_model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'use_time_features': False\n",
    "}\n",
    "\n",
    "print(\"✅ Configurações definidas:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados carregados:\n",
      "  - Conceitos: 251\n",
      "  - Questões: 680\n",
      "  - Interações: 4499\n",
      "  - Estudantes únicos: 100\n"
     ]
    }
   ],
   "source": [
    "with open('data/json/concepts_graph.json', 'r', encoding='utf-8') as f:\n",
    "    concepts_data = json.load(f)\n",
    "concepts = concepts_data['concepts']\n",
    "\n",
    "with open('data/json/questions_graph.json', 'r', encoding='utf-8') as f:\n",
    "    questions_data = json.load(f)\n",
    "questions = questions_data['questions']\n",
    "\n",
    "with open('data/output/notebooks/geracao_respostas_llm/interactions_complete.json', 'r', encoding='utf-8') as f:\n",
    "    interactions_data = json.load(f)\n",
    "interactions = interactions_data['interactions']\n",
    "\n",
    "print(f\"✅ Dados carregados:\")\n",
    "print(f\"  - Conceitos: {len(concepts)}\")\n",
    "print(f\"  - Questões: {len(questions)}\")\n",
    "print(f\"  - Interações: {len(interactions)}\")\n",
    "print(f\"  - Estudantes únicos: {len(set(i['student_id'] for i in interactions))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados preparados:\n",
      "  - Conceitos indexados: 251\n",
      "  - Questões indexadas: 680\n",
      "  - Estudantes com sequências: 100\n",
      "  - Média de interações por estudante: 44.99\n"
     ]
    }
   ],
   "source": [
    "concept_id_to_idx = {c['id']: idx for idx, c in enumerate(concepts)}\n",
    "question_id_to_idx = {q['id']: idx for idx, q in enumerate(questions)}\n",
    "\n",
    "question_to_concepts = {}\n",
    "for q_idx, q in enumerate(questions):\n",
    "    c_id = q['c_id']\n",
    "    if c_id in concept_id_to_idx:\n",
    "        c_idx = concept_id_to_idx[c_id]\n",
    "        question_to_concepts[q_idx] = [c_idx]\n",
    "\n",
    "error_type_to_idx = {\n",
    "    'slip': 0,\n",
    "    'misconception': 1,\n",
    "    'careless': 2,\n",
    "    'incomplete': 3,\n",
    "    'misunderstanding': 4,\n",
    "    None: 5\n",
    "}\n",
    "\n",
    "question_type_to_idx = {\n",
    "    'multiple_choice': 0,\n",
    "    'descriptive': 1\n",
    "}\n",
    "\n",
    "student_sequences = defaultdict(list)\n",
    "for interaction in interactions:\n",
    "    student_id = interaction['student_id']\n",
    "    q_id = interaction['question_id']\n",
    "    is_correct = interaction['is_correct']\n",
    "    error_type = interaction.get('error_type')\n",
    "    question_type = interaction.get('question_type', 'multiple_choice')\n",
    "    \n",
    "    if q_id in question_id_to_idx:\n",
    "        student_sequences[student_id].append({\n",
    "            'question_idx': question_id_to_idx[q_id],\n",
    "            'is_correct': int(is_correct),\n",
    "            'timestamp': interaction['timestamp'],\n",
    "            'error_type_idx': error_type_to_idx.get(error_type, 5),\n",
    "            'question_type_idx': question_type_to_idx.get(question_type, 0)\n",
    "        })\n",
    "\n",
    "for student_id in student_sequences:\n",
    "    student_sequences[student_id].sort(key=lambda x: x['timestamp'])\n",
    "\n",
    "print(f\"✅ Dados preparados:\")\n",
    "print(f\"  - Conceitos indexados: {len(concept_id_to_idx)}\")\n",
    "print(f\"  - Questões indexadas: {len(question_id_to_idx)}\")\n",
    "print(f\"  - Estudantes com sequências: {len(student_sequences)}\")\n",
    "print(f\"  - Média de interações por estudante: {np.mean([len(seq) for seq in student_sequences.values()]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIEnc: Textual Information Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando modelo de embeddings...\n",
      "Gerando embeddings de conceitos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a415a202cc42608d71a80d775249f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando embeddings de questões...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7616df8cc004cfbac6d0a8217a36099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Embeddings gerados:\n",
      "  - Conceitos: torch.Size([251, 384])\n",
      "  - Questões: torch.Size([680, 384])\n"
     ]
    }
   ],
   "source": [
    "print(\"Carregando modelo de embeddings...\")\n",
    "embedding_model = SentenceTransformer(config['plm_model'])\n",
    "\n",
    "concept_texts = []\n",
    "for c in concepts:\n",
    "    text = f\"{c['nome']}: {c['definicao']}\"\n",
    "    concept_texts.append(text)\n",
    "\n",
    "question_texts = []\n",
    "for q in questions:\n",
    "    text = f\"{q['q']} {q.get('exp', '')}\"\n",
    "    question_texts.append(text)\n",
    "\n",
    "print(\"Gerando embeddings de conceitos...\")\n",
    "concept_embeddings = embedding_model.encode(concept_texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "print(\"Gerando embeddings de questões...\")\n",
    "question_embeddings = embedding_model.encode(question_texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "concept_embeddings_tensor = torch.FloatTensor(concept_embeddings).to(device)\n",
    "question_embeddings_tensor = torch.FloatTensor(question_embeddings).to(device)\n",
    "\n",
    "print(f\"\\n✅ Embeddings gerados:\")\n",
    "print(f\"  - Conceitos: {concept_embeddings_tensor.shape}\")\n",
    "print(f\"  - Questões: {question_embeddings_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção do Grafo Heterogêneo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ StructuralInformationEncoder definido\n"
     ]
    }
   ],
   "source": [
    "class StructuralInformationEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads=4, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.concept_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.question_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.c_to_c_convs = nn.ModuleList()\n",
    "        self.c_to_q_convs = nn.ModuleList()\n",
    "        self.q_to_c_convs = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            self.c_to_c_convs.append(GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout, add_self_loops=False))\n",
    "            self.c_to_q_convs.append(GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout, add_self_loops=False))\n",
    "            self.q_to_c_convs.append(GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, dropout=dropout, add_self_loops=False))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        x_c = self.concept_proj(graph_data['concept'].x)\n",
    "        x_q = self.question_proj(graph_data['question'].x)\n",
    "        \n",
    "        x_c_original = x_c.clone()\n",
    "        x_q_original = x_q.clone()\n",
    "        \n",
    "        for layer in range(self.num_layers):\n",
    "            x_c_new = x_c.clone()\n",
    "            x_q_new = x_q.clone()\n",
    "            \n",
    "            if ('concept', 'prerequisite', 'concept') in graph_data.edge_types:\n",
    "                edge_index_c_c = graph_data['concept', 'prerequisite', 'concept'].edge_index\n",
    "                if edge_index_c_c.size(1) > 0:\n",
    "                    x_c_from_c = self.c_to_c_convs[layer](x_c, edge_index_c_c)\n",
    "                    x_c_new = x_c_new + x_c_from_c\n",
    "            \n",
    "            if ('concept', 'has_question', 'question') in graph_data.edge_types:\n",
    "                edge_index_c_q = graph_data['concept', 'has_question', 'question'].edge_index\n",
    "                if edge_index_c_q.size(1) > 0:\n",
    "                    x_q_from_c = self.c_to_q_convs[layer]((x_c, x_q), edge_index_c_q)\n",
    "                    x_q_new = x_q_new + x_q_from_c\n",
    "            \n",
    "            if ('question', 'relates_to', 'concept') in graph_data.edge_types:\n",
    "                edge_index_q_c = graph_data['question', 'relates_to', 'concept'].edge_index\n",
    "                if edge_index_q_c.size(1) > 0:\n",
    "                    x_c_from_q = self.q_to_c_convs[layer]((x_q, x_c), edge_index_q_c)\n",
    "                    x_c_new = x_c_new + x_c_from_q\n",
    "            \n",
    "            x_c = F.relu(x_c_new)\n",
    "            x_q = F.relu(x_q_new)\n",
    "            x_c = self.dropout(x_c)\n",
    "            x_q = self.dropout(x_q)\n",
    "        \n",
    "        x_c = x_c + x_c_original\n",
    "        x_q = x_q + x_q_original\n",
    "        \n",
    "        return x_c, x_q\n",
    "\n",
    "print(\"✅ StructuralInformationEncoder definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grafo heterogêneo construído:\n",
      "  - Nós de conceitos: 251\n",
      "  - Nós de questões: 680\n",
      "  - Arestas question->concept: 680\n",
      "  - Arestas concept->question: 680\n",
      "  - Arestas concept->concept: 322\n"
     ]
    }
   ],
   "source": [
    "graph_data = HeteroData()\n",
    "\n",
    "graph_data['concept'].x = concept_embeddings_tensor\n",
    "graph_data['question'].x = question_embeddings_tensor\n",
    "\n",
    "q_to_c_edges = []\n",
    "c_to_q_edges = []\n",
    "\n",
    "for q_idx, q in enumerate(questions):\n",
    "    c_id = q['c_id']\n",
    "    if c_id in concept_id_to_idx:\n",
    "        c_idx = concept_id_to_idx[c_id]\n",
    "        q_to_c_edges.append([q_idx, c_idx])\n",
    "        c_to_q_edges.append([c_idx, q_idx])\n",
    "\n",
    "if q_to_c_edges:\n",
    "    graph_data['question', 'relates_to', 'concept'].edge_index = torch.LongTensor(q_to_c_edges).t().contiguous().to(device)\n",
    "    graph_data['concept', 'has_question', 'question'].edge_index = torch.LongTensor(c_to_q_edges).t().contiguous().to(device)\n",
    "\n",
    "c_to_c_edges = []\n",
    "if 'relations' in concepts_data:\n",
    "    for rel in concepts_data['relations']:\n",
    "        source_id = rel.get('source_id')\n",
    "        target_id = rel.get('target_id')\n",
    "        if source_id in concept_id_to_idx and target_id in concept_id_to_idx:\n",
    "            source_idx = concept_id_to_idx[source_id]\n",
    "            target_idx = concept_id_to_idx[target_id]\n",
    "            c_to_c_edges.append([source_idx, target_idx])\n",
    "\n",
    "if c_to_c_edges:\n",
    "    graph_data['concept', 'prerequisite', 'concept'].edge_index = torch.LongTensor(c_to_c_edges).t().contiguous().to(device)\n",
    "\n",
    "print(f\"✅ Grafo heterogêneo construído:\")\n",
    "print(f\"  - Nós de conceitos: {graph_data['concept'].x.shape[0]}\")\n",
    "print(f\"  - Nós de questões: {graph_data['question'].x.shape[0]}\")\n",
    "print(f\"  - Arestas question->concept: {len(q_to_c_edges)}\")\n",
    "print(f\"  - Arestas concept->question: {len(c_to_q_edges)}\")\n",
    "print(f\"  - Arestas concept->concept: {len(c_to_c_edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ StudentStateEncoder e ResponsePredictor definidos\n"
     ]
    }
   ],
   "source": [
    "class StudentStateEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, dropout=0.3, use_time_features=False):\n",
    "        super().__init__()\n",
    "        self.use_time_features = use_time_features\n",
    "        \n",
    "        input_size = hidden_dim * 2\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, concept_vecs_seq, responses_seq, time_features_seq=None):\n",
    "        batch_size, seq_len, hidden_dim = concept_vecs_seq.shape\n",
    "        \n",
    "        v_seq = []\n",
    "        for t in range(seq_len):\n",
    "            u_t = concept_vecs_seq[:, t, :]\n",
    "            r_t = responses_seq[:, t].unsqueeze(1)\n",
    "            \n",
    "            correct_part = u_t * r_t\n",
    "            incorrect_part = u_t * (1 - r_t)\n",
    "            \n",
    "            v_t = torch.cat([correct_part, incorrect_part], dim=1)\n",
    "            \n",
    "            v_seq.append(v_t)\n",
    "        \n",
    "        v_seq = torch.stack(v_seq, dim=1)\n",
    "        \n",
    "        h_seq, _ = self.gru(v_seq)\n",
    "        h_seq = self.dropout(h_seq)\n",
    "        \n",
    "        return h_seq\n",
    "\n",
    "class ResponsePredictor(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, h_t, q_next, u_next):\n",
    "        combined = torch.cat([h_t, q_next, u_next], dim=1)\n",
    "        pred = self.fc(combined)\n",
    "        return pred.squeeze(-1)\n",
    "\n",
    "print(\"✅ StudentStateEncoder e ResponsePredictor definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo SINKT definido\n"
     ]
    }
   ],
   "source": [
    "class SINKT(nn.Module):\n",
    "    def __init__(self, config, graph_data, question_to_concepts):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.graph_data = graph_data\n",
    "        self.question_to_concepts = question_to_concepts\n",
    "        \n",
    "        self.sienc = StructuralInformationEncoder(\n",
    "            input_dim=config['text_embed_dim'],\n",
    "            hidden_dim=config['hidden_dim'],\n",
    "            num_heads=config['gat_heads'],\n",
    "            num_layers=config['gat_layers'],\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "        \n",
    "        self.student_encoder = StudentStateEncoder(\n",
    "            hidden_dim=config['hidden_dim'],\n",
    "            num_layers=config['gru_layers'],\n",
    "            dropout=config['dropout'],\n",
    "            use_time_features=config.get('use_time_features', False)\n",
    "        )\n",
    "        \n",
    "        self.response_predictor = ResponsePredictor(\n",
    "            hidden_dim=config['hidden_dim'],\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "        \n",
    "    def forward(self, question_seq, response_seq, time_seq=None):\n",
    "        concept_embeds, question_embeds = self.sienc(self.graph_data)\n",
    "        \n",
    "        batch_size, seq_len = question_seq.shape\n",
    "        device = question_seq.device\n",
    "        \n",
    "        concept_vecs_seq = []\n",
    "        for t in range(seq_len):\n",
    "            q_indices = question_seq[:, t]\n",
    "            \n",
    "            batch_concept_vecs = []\n",
    "            for b in range(batch_size):\n",
    "                q_idx = q_indices[b].item()\n",
    "                \n",
    "                if q_idx in self.question_to_concepts and len(self.question_to_concepts[q_idx]) > 0:\n",
    "                    c_indices = self.question_to_concepts[q_idx]\n",
    "                    c_indices_tensor = torch.tensor(c_indices, dtype=torch.long, device=device)\n",
    "                    c_vecs = concept_embeds[c_indices_tensor]\n",
    "                    u_t = c_vecs.mean(dim=0)\n",
    "                else:\n",
    "                    u_t = torch.zeros(self.config['hidden_dim'], device=device)\n",
    "                batch_concept_vecs.append(u_t)\n",
    "            \n",
    "            concept_vecs_seq.append(torch.stack(batch_concept_vecs))\n",
    "        \n",
    "        concept_vecs_seq = torch.stack(concept_vecs_seq, dim=1)\n",
    "        \n",
    "        h_seq = self.student_encoder(concept_vecs_seq, response_seq.float(), time_seq)\n",
    "        \n",
    "        predictions = []\n",
    "        for t in range(seq_len - 1):\n",
    "            h_t = h_seq[:, t, :]\n",
    "            \n",
    "            q_next_indices = question_seq[:, t + 1]\n",
    "            q_next_vecs = question_embeds[q_next_indices]\n",
    "            \n",
    "            u_next_vecs = concept_vecs_seq[:, t + 1, :]\n",
    "            \n",
    "            pred = self.response_predictor(h_t, q_next_vecs, u_next_vecs)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        predictions = torch.stack(predictions, dim=1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "print(\"✅ Modelo SINKT definido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset e DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset e collate_fn definidos\n"
     ]
    }
   ],
   "source": [
    "class KTDataset(Dataset):\n",
    "    def __init__(self, student_sequences, min_seq_len=3):\n",
    "        self.sequences = []\n",
    "        \n",
    "        for student_id, seq in student_sequences.items():\n",
    "            if len(seq) >= min_seq_len:\n",
    "                question_seq = [s['question_idx'] for s in seq]\n",
    "                response_seq = [s['is_correct'] for s in seq]\n",
    "                error_type_seq = [s.get('error_type_idx', 5) for s in seq]\n",
    "                question_type_seq = [s.get('question_type_idx', 0) for s in seq]\n",
    "                \n",
    "                self.sequences.append({\n",
    "                    'student_id': student_id,\n",
    "                    'questions': question_seq,\n",
    "                    'responses': response_seq,\n",
    "                    'error_types': error_type_seq,\n",
    "                    'question_types': question_type_seq\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(len(item['questions']) for item in batch)\n",
    "    \n",
    "    question_seqs = []\n",
    "    response_seqs = []\n",
    "    masks = []\n",
    "    \n",
    "    for item in batch:\n",
    "        q_seq = item['questions']\n",
    "        r_seq = item['responses']\n",
    "        seq_len = len(q_seq)\n",
    "        \n",
    "        padding_len = max_len - seq_len\n",
    "        q_seq_padded = q_seq + [0] * padding_len\n",
    "        r_seq_padded = r_seq + [0] * padding_len\n",
    "        mask = [1] * seq_len + [0] * padding_len\n",
    "        \n",
    "        question_seqs.append(q_seq_padded)\n",
    "        response_seqs.append(r_seq_padded)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return {\n",
    "        'questions': torch.LongTensor(question_seqs),\n",
    "        'responses': torch.LongTensor(response_seqs),\n",
    "        'masks': torch.FloatTensor(masks)\n",
    "    }\n",
    "\n",
    "print(\"✅ Dataset e collate_fn definidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funções de treinamento e avaliação definidas\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        questions = batch['questions'].to(device)\n",
    "        responses = batch['responses'].to(device)\n",
    "        masks = batch['masks'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(questions, responses)\n",
    "        \n",
    "        targets = responses[:, 1:].float()\n",
    "        pred_mask = masks[:, 1:]\n",
    "        \n",
    "        loss = criterion(predictions, targets)\n",
    "        loss = (loss * pred_mask).sum() / pred_mask.sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        valid_preds = predictions[pred_mask == 1].detach().cpu().numpy()\n",
    "        valid_labels = targets[pred_mask == 1].detach().cpu().numpy()\n",
    "        all_preds.extend(valid_preds)\n",
    "        all_labels.extend(valid_labels)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    if len(set(all_labels)) > 1:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    else:\n",
    "        auc = 0.5\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            questions = batch['questions'].to(device)\n",
    "            responses = batch['responses'].to(device)\n",
    "            masks = batch['masks'].to(device)\n",
    "            \n",
    "            predictions = model(questions, responses)\n",
    "            \n",
    "            targets = responses[:, 1:].float()\n",
    "            pred_mask = masks[:, 1:]\n",
    "            \n",
    "            loss = criterion(predictions, targets)\n",
    "            loss = (loss * pred_mask).sum() / pred_mask.sum()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            valid_preds = predictions[pred_mask == 1].cpu().numpy()\n",
    "            valid_labels = targets[pred_mask == 1].cpu().numpy()\n",
    "            all_preds.extend(valid_preds)\n",
    "            all_labels.extend(valid_labels)\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    if len(set(all_labels)) > 1:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    else:\n",
    "        auc = 0.5\n",
    "    \n",
    "    binary_preds = [1 if p > 0.5 else 0 for p in all_preds]\n",
    "    acc = accuracy_score(all_labels, binary_preds)\n",
    "    f1 = f1_score(all_labels, binary_preds, zero_division=0)\n",
    "    precision = precision_score(all_labels, binary_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, binary_preds, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'auc': auc,\n",
    "        'acc': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "print(\"✅ Funções de treinamento e avaliação definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados divididos:\n",
      "  - Train: 70 sequências (70 estudantes)\n",
      "  - Val: 15 sequências (15 estudantes)\n",
      "  - Test: 15 sequências (15 estudantes)\n"
     ]
    }
   ],
   "source": [
    "student_ids = list(student_sequences.keys())\n",
    "train_ids, temp_ids = train_test_split(student_ids, train_size=config['train_split'], random_state=SEED)\n",
    "val_size_adjusted = config['val_split'] / (config['val_split'] + config['test_split'])\n",
    "val_ids, test_ids = train_test_split(temp_ids, train_size=val_size_adjusted, random_state=SEED)\n",
    "\n",
    "train_sequences = {sid: student_sequences[sid] for sid in train_ids}\n",
    "val_sequences = {sid: student_sequences[sid] for sid in val_ids}\n",
    "test_sequences = {sid: student_sequences[sid] for sid in test_ids}\n",
    "\n",
    "train_dataset = KTDataset(train_sequences)\n",
    "val_dataset = KTDataset(val_sequences)\n",
    "test_dataset = KTDataset(test_sequences)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"✅ Dados divididos:\")\n",
    "print(f\"  - Train: {len(train_dataset)} sequências ({len(train_ids)} estudantes)\")\n",
    "print(f\"  - Val: {len(val_dataset)} sequências ({len(val_ids)} estudantes)\")\n",
    "print(f\"  - Test: {len(test_dataset)} sequências ({len(test_ids)} estudantes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo inicializado\n",
      "  - Parâmetros totais: 504,065\n",
      "  - Parâmetros treináveis: 504,065\n"
     ]
    }
   ],
   "source": [
    "model = SINKT(config, graph_data, question_to_concepts).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "\n",
    "print(f\"✅ Modelo inicializado\")\n",
    "print(f\"  - Parâmetros totais: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  - Parâmetros treináveis: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando treinamento...\n",
      "\n",
      "Epoch 1/50\n",
      "  Train Loss: 0.6778 | Train AUC: 0.5029\n",
      "  Val Loss: 0.7000 | AUC: 0.7609 | ACC: 0.4593 | F1: 0.0000\n",
      "  ✅ Novo melhor modelo (AUC: 0.7609)\n",
      "\n",
      "Epoch 2/50\n",
      "  Train Loss: 0.6453 | Train AUC: 0.6295\n",
      "  Val Loss: 0.7001 | AUC: 0.7831 | ACC: 0.4593 | F1: 0.0000\n",
      "  ✅ Novo melhor modelo (AUC: 0.7831)\n",
      "\n",
      "Epoch 3/50\n",
      "  Train Loss: 0.5787 | Train AUC: 0.7838\n",
      "  Val Loss: 0.6500 | AUC: 0.7881 | ACC: 0.4593 | F1: 0.0000\n",
      "  ✅ Novo melhor modelo (AUC: 0.7881)\n",
      "\n",
      "Epoch 4/50\n",
      "  Train Loss: 0.5805 | Train AUC: 0.8154\n",
      "  Val Loss: 0.5953 | AUC: 0.7907 | ACC: 0.7739 | F1: 0.7990\n",
      "  ✅ Novo melhor modelo (AUC: 0.7907)\n",
      "\n",
      "Epoch 5/50\n",
      "  Train Loss: 0.5327 | Train AUC: 0.8194\n",
      "  Val Loss: 0.5728 | AUC: 0.7942 | ACC: 0.7612 | F1: 0.8041\n",
      "  ✅ Novo melhor modelo (AUC: 0.7942)\n",
      "\n",
      "Epoch 6/50\n",
      "  Train Loss: 0.4968 | Train AUC: 0.8196\n",
      "  Val Loss: 0.5414 | AUC: 0.7966 | ACC: 0.7683 | F1: 0.8075\n",
      "  ✅ Novo melhor modelo (AUC: 0.7966)\n",
      "\n",
      "Epoch 7/50\n",
      "  Train Loss: 0.5033 | Train AUC: 0.8284\n",
      "  Val Loss: 0.5257 | AUC: 0.7967 | ACC: 0.7711 | F1: 0.8039\n",
      "  ✅ Novo melhor modelo (AUC: 0.7967)\n",
      "\n",
      "Epoch 8/50\n",
      "  Train Loss: 0.4602 | Train AUC: 0.8197\n",
      "  Val Loss: 0.5221 | AUC: 0.7963 | ACC: 0.7725 | F1: 0.8010\n",
      "  Patience: 1/10\n",
      "\n",
      "Epoch 9/50\n",
      "  Train Loss: 0.4703 | Train AUC: 0.8266\n",
      "  Val Loss: 0.5227 | AUC: 0.7962 | ACC: 0.7739 | F1: 0.8015\n",
      "  Patience: 2/10\n",
      "\n",
      "Epoch 10/50\n",
      "  Train Loss: 0.4914 | Train AUC: 0.8257\n",
      "  Val Loss: 0.5211 | AUC: 0.7957 | ACC: 0.7725 | F1: 0.7995\n",
      "  Patience: 3/10\n",
      "\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.4718 | Train AUC: 0.8245\n",
      "  Val Loss: 0.5215 | AUC: 0.7953 | ACC: 0.7725 | F1: 0.7995\n",
      "  Patience: 4/10\n",
      "\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.4563 | Train AUC: 0.8301\n",
      "  Val Loss: 0.5253 | AUC: 0.7950 | ACC: 0.7739 | F1: 0.8005\n",
      "  Patience: 5/10\n",
      "\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.4840 | Train AUC: 0.8322\n",
      "  Val Loss: 0.5259 | AUC: 0.7957 | ACC: 0.7711 | F1: 0.7995\n",
      "  Patience: 6/10\n",
      "\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.4995 | Train AUC: 0.8274\n",
      "  Val Loss: 0.5221 | AUC: 0.7969 | ACC: 0.7711 | F1: 0.8015\n",
      "  ✅ Novo melhor modelo (AUC: 0.7969)\n",
      "\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.4487 | Train AUC: 0.8283\n",
      "  Val Loss: 0.5187 | AUC: 0.7978 | ACC: 0.7753 | F1: 0.8058\n",
      "  ✅ Novo melhor modelo (AUC: 0.7978)\n",
      "\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.4613 | Train AUC: 0.8307\n",
      "  Val Loss: 0.5181 | AUC: 0.7980 | ACC: 0.7739 | F1: 0.8048\n",
      "  ✅ Novo melhor modelo (AUC: 0.7980)\n",
      "\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.4619 | Train AUC: 0.8316\n",
      "  Val Loss: 0.5197 | AUC: 0.7977 | ACC: 0.7753 | F1: 0.8049\n",
      "  Patience: 1/10\n",
      "\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.4930 | Train AUC: 0.8300\n",
      "  Val Loss: 0.5203 | AUC: 0.7976 | ACC: 0.7767 | F1: 0.8059\n",
      "  Patience: 2/10\n",
      "\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.4727 | Train AUC: 0.8318\n",
      "  Val Loss: 0.5189 | AUC: 0.7980 | ACC: 0.7753 | F1: 0.8054\n",
      "  Patience: 3/10\n",
      "\n",
      "Epoch 20/50\n",
      "  Train Loss: 0.4777 | Train AUC: 0.8299\n",
      "  Val Loss: 0.5189 | AUC: 0.7988 | ACC: 0.7711 | F1: 0.8019\n",
      "  ✅ Novo melhor modelo (AUC: 0.7988)\n",
      "\n",
      "Epoch 21/50\n",
      "  Train Loss: 0.4833 | Train AUC: 0.8366\n",
      "  Val Loss: 0.5219 | AUC: 0.7986 | ACC: 0.7669 | F1: 0.7966\n",
      "  Patience: 1/10\n",
      "\n",
      "Epoch 22/50\n",
      "  Train Loss: 0.4721 | Train AUC: 0.8351\n",
      "  Val Loss: 0.5245 | AUC: 0.7981 | ACC: 0.7711 | F1: 0.8000\n",
      "  Patience: 2/10\n",
      "\n",
      "Epoch 23/50\n",
      "  Train Loss: 0.4392 | Train AUC: 0.8377\n",
      "  Val Loss: 0.5259 | AUC: 0.7986 | ACC: 0.7697 | F1: 0.7985\n",
      "  Patience: 3/10\n",
      "\n",
      "Epoch 24/50\n",
      "  Train Loss: 0.4585 | Train AUC: 0.8333\n",
      "  Val Loss: 0.5275 | AUC: 0.7999 | ACC: 0.7725 | F1: 0.8024\n",
      "  ✅ Novo melhor modelo (AUC: 0.7999)\n",
      "\n",
      "Epoch 25/50\n",
      "  Train Loss: 0.4707 | Train AUC: 0.8352\n",
      "  Val Loss: 0.5232 | AUC: 0.7989 | ACC: 0.7753 | F1: 0.8058\n",
      "  Patience: 1/10\n",
      "\n",
      "Epoch 26/50\n",
      "  Train Loss: 0.4433 | Train AUC: 0.8407\n",
      "  Val Loss: 0.5231 | AUC: 0.7977 | ACC: 0.7753 | F1: 0.8049\n",
      "  Patience: 2/10\n",
      "\n",
      "Epoch 27/50\n",
      "  Train Loss: 0.4592 | Train AUC: 0.8369\n",
      "  Val Loss: 0.5255 | AUC: 0.7971 | ACC: 0.7753 | F1: 0.8039\n",
      "  Patience: 3/10\n",
      "\n",
      "Epoch 28/50\n",
      "  Train Loss: 0.4742 | Train AUC: 0.8436\n",
      "  Val Loss: 0.5217 | AUC: 0.7976 | ACC: 0.7767 | F1: 0.8063\n",
      "  Patience: 4/10\n",
      "\n",
      "Epoch 29/50\n",
      "  Train Loss: 0.4560 | Train AUC: 0.8412\n",
      "  Val Loss: 0.5214 | AUC: 0.7975 | ACC: 0.7767 | F1: 0.8077\n",
      "  Patience: 5/10\n",
      "\n",
      "Epoch 30/50\n",
      "  Train Loss: 0.4551 | Train AUC: 0.8429\n",
      "  Val Loss: 0.5231 | AUC: 0.7956 | ACC: 0.7767 | F1: 0.8063\n",
      "  Patience: 6/10\n",
      "\n",
      "Epoch 31/50\n",
      "  Train Loss: 0.4400 | Train AUC: 0.8429\n",
      "  Val Loss: 0.5311 | AUC: 0.7931 | ACC: 0.7725 | F1: 0.8010\n",
      "  Patience: 7/10\n",
      "\n",
      "Epoch 32/50\n",
      "  Train Loss: 0.4656 | Train AUC: 0.8482\n",
      "  Val Loss: 0.5296 | AUC: 0.7922 | ACC: 0.7739 | F1: 0.8025\n",
      "  Patience: 8/10\n",
      "\n",
      "Epoch 33/50\n",
      "  Train Loss: 0.4775 | Train AUC: 0.8529\n",
      "  Val Loss: 0.5249 | AUC: 0.7908 | ACC: 0.7795 | F1: 0.8092\n",
      "  Patience: 9/10\n",
      "\n",
      "Epoch 34/50\n",
      "  Train Loss: 0.4502 | Train AUC: 0.8537\n",
      "  Val Loss: 0.5275 | AUC: 0.7914 | ACC: 0.7795 | F1: 0.8097\n",
      "  Patience: 10/10\n",
      "\n",
      "Early stopping acionado na época 34\n",
      "\n",
      "✅ Treinamento concluído!\n",
      "  - Melhor AUC de validação: 0.7999\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_auc': [],\n",
    "    'val_loss': [],\n",
    "    'val_auc': [],\n",
    "    'val_acc': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "best_val_auc = 0\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"Iniciando treinamento...\\n\")\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    print(f\"Epoch {epoch + 1}/{config['num_epochs']}\")\n",
    "    \n",
    "    train_loss, train_auc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_auc'].append(train_auc)\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_auc'].append(val_metrics['auc'])\n",
    "    history['val_acc'].append(val_metrics['acc'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    \n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f} | AUC: {val_metrics['auc']:.4f} | ACC: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "    \n",
    "    if val_metrics['auc'] > best_val_auc:\n",
    "        best_val_auc = val_metrics['auc']\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ✅ Novo melhor modelo (AUC: {best_val_auc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  Patience: {patience_counter}/{config['early_stopping_patience']}\")\n",
    "    \n",
    "    if patience_counter >= config['early_stopping_patience']:\n",
    "        print(f\"\\nEarly stopping acionado na época {epoch + 1}\")\n",
    "        break\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"\\n✅ Treinamento concluído!\")\n",
    "print(f\"  - Melhor AUC de validação: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Melhor modelo carregado para avaliação final\n",
      "\n",
      "✅ Avaliação no Conjunto de Teste:\n",
      "  - Loss:      0.4913\n",
      "  - AUC:       0.8218\n",
      "  - Accuracy:  0.7869\n",
      "  - F1-Score:  0.7360\n",
      "  - Precision: 0.6996\n",
      "  - Recall:    0.7763\n"
     ]
    }
   ],
   "source": [
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"✅ Melhor modelo carregado para avaliação final\")\n",
    "\n",
    "test_metrics = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n✅ Avaliação no Conjunto de Teste:\")\n",
    "print(f\"  - Loss:      {test_metrics['loss']:.4f}\")\n",
    "print(f\"  - AUC:       {test_metrics['auc']:.4f}\")\n",
    "print(f\"  - Accuracy:  {test_metrics['acc']:.4f}\")\n",
    "print(f\"  - F1-Score:  {test_metrics['f1']:.4f}\")\n",
    "print(f\"  - Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  - Recall:    {test_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matriz de confusão salva em: data/output/notebooks/treinamento_sinkt/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        questions = batch['questions'].to(device)\n",
    "        responses = batch['responses'].to(device)\n",
    "        masks = batch['masks'].to(device)\n",
    "        \n",
    "        predictions = model(questions, responses)\n",
    "        \n",
    "        targets = responses[:, 1:].float()\n",
    "        pred_masks = masks[:, 1:]\n",
    "        \n",
    "        valid_preds = predictions[pred_masks == 1].cpu().numpy()\n",
    "        valid_targets = targets[pred_masks == 1].cpu().numpy()\n",
    "        \n",
    "        all_preds.extend(valid_preds)\n",
    "        all_targets.extend(valid_targets)\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "all_preds_binary = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds_binary)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Incorreto', 'Correto'],\n",
    "            yticklabels=['Incorreto', 'Correto'])\n",
    "plt.xlabel('Predição')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão - Conjunto de Teste')\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/output/notebooks/treinamento_sinkt/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Matriz de confusão salva em: data/output/notebooks/treinamento_sinkt/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Detalhada de Predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas por Tipo de Erro:\n",
      "============================================================\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "error_type_predictions = defaultdict(lambda: {'preds': [], 'targets': []})\n",
    "\n",
    "idx_to_error_type = {v: k for k, v in error_type_to_idx.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        questions = batch['questions'].to(device)\n",
    "        responses = batch['responses'].to(device)\n",
    "        masks = batch['masks'].to(device)\n",
    "        \n",
    "        predictions = model(questions, responses)\n",
    "        \n",
    "        targets = responses[:, 1:].float()\n",
    "        pred_masks = masks[:, 1:]\n",
    "        \n",
    "        batch_size = questions.size(0)\n",
    "        for b in range(batch_size):\n",
    "            student_idx = batch_idx * config['batch_size'] + b\n",
    "            if student_idx >= len(test_dataset):\n",
    "                break\n",
    "            \n",
    "            student_data = test_dataset.sequences[student_idx]\n",
    "            error_types_seq = student_data.get('error_types', [])\n",
    "            \n",
    "            for t in range(predictions.size(1)):\n",
    "                if pred_masks[b, t] == 1:\n",
    "                    if t + 1 < len(error_types_seq):\n",
    "                        error_type_idx = error_types_seq[t + 1]\n",
    "                        error_type = idx_to_error_type.get(error_type_idx, 'unknown')\n",
    "                        \n",
    "                        pred_val = predictions[b, t].cpu().item()\n",
    "                        target_val = targets[b, t].cpu().item()\n",
    "                        \n",
    "                        error_type_predictions[error_type]['preds'].append(pred_val)\n",
    "                        error_type_predictions[error_type]['targets'].append(target_val)\n",
    "\n",
    "print(\"Métricas por Tipo de Erro:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "error_metrics = {}\n",
    "for error_type, data in error_type_predictions.items():\n",
    "    if len(data['targets']) > 10:\n",
    "        preds = np.array(data['preds'])\n",
    "        targets = np.array(data['targets'])\n",
    "        \n",
    "        if len(np.unique(targets)) > 1:\n",
    "            auc = roc_auc_score(targets, preds)\n",
    "            acc = accuracy_score(targets, (preds >= 0.5).astype(int))\n",
    "            f1 = f1_score(targets, (preds >= 0.5).astype(int), zero_division=0)\n",
    "            \n",
    "            error_metrics[error_type] = {'auc': auc, 'acc': acc, 'f1': f1, 'count': len(targets)}\n",
    "            \n",
    "            print(f\"\\n{error_type}:\")\n",
    "            print(f\"  - Amostras: {len(targets)}\")\n",
    "            print(f\"  - AUC: {auc:.4f}\")\n",
    "            print(f\"  - Accuracy: {acc:.4f}\")\n",
    "            print(f\"  - F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise por Tipo de Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados insuficientes para análise por tipo de erro\n"
     ]
    }
   ],
   "source": [
    "if error_metrics:\n",
    "    error_types_list = list(error_metrics.keys())\n",
    "    auc_values = [error_metrics[et]['auc'] for et in error_types_list]\n",
    "    acc_values = [error_metrics[et]['acc'] for et in error_types_list]\n",
    "    f1_values = [error_metrics[et]['f1'] for et in error_types_list]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    x_pos = np.arange(len(error_types_list))\n",
    "    \n",
    "    axes[0].bar(x_pos, auc_values, color='#2ecc71', alpha=0.7)\n",
    "    axes[0].set_xticks(x_pos)\n",
    "    axes[0].set_xticklabels(error_types_list, rotation=45, ha='right')\n",
    "    axes[0].set_ylabel('AUC')\n",
    "    axes[0].set_title('AUC por Tipo de Erro')\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    axes[1].bar(x_pos, acc_values, color='#3498db', alpha=0.7)\n",
    "    axes[1].set_xticks(x_pos)\n",
    "    axes[1].set_xticklabels(error_types_list, rotation=45, ha='right')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy por Tipo de Erro')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    axes[2].bar(x_pos, f1_values, color='#e74c3c', alpha=0.7)\n",
    "    axes[2].set_xticks(x_pos)\n",
    "    axes[2].set_xticklabels(error_types_list, rotation=45, ha='right')\n",
    "    axes[2].set_ylabel('F1-Score')\n",
    "    axes[2].set_title('F1-Score por Tipo de Erro')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/output/notebooks/treinamento_sinkt/metrics_by_error_type.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Gráficos de métricas por tipo de erro salvos\")\n",
    "else:\n",
    "    print(\"Dados insuficientes para análise por tipo de erro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização de Métricas por Tipo de Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Dados insuficientes para análise por tipo de erro\n"
     ]
    }
   ],
   "source": [
    "if error_metrics:\n",
    "    error_types_list = list(error_metrics.keys())\n",
    "    auc_values = [error_metrics[et]['auc'] for et in error_types_list]\n",
    "    acc_values = [error_metrics[et]['acc'] for et in error_types_list]\n",
    "    f1_values = [error_metrics[et]['f1'] for et in error_types_list]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    x_pos = np.arange(len(error_types_list))\n",
    "    \n",
    "    axes[0].bar(x_pos, auc_values, color='#2ecc71', alpha=0.7)\n",
    "    axes[0].set_xticks(x_pos)\n",
    "    axes[0].set_xticklabels(error_types_list, rotation=45, ha='right')\n",
    "    axes[0].set_ylabel('AUC')\n",
    "    axes[0].set_title('AUC por Tipo de Erro')\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    axes[1].bar(x_pos, acc_values, color='#3498db', alpha=0.7)\n",
    "    axes[1].set_xticks(x_pos)\n",
    "    axes[1].set_xticklabels(error_types_list, rotation=45, ha='right')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy por Tipo de Erro')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    axes[2].bar(x_pos, f1_values, color='#e74c3c', alpha=0.7)\n",
    "    axes[2].set_xticks(x_pos)\n",
    "    axes[2].set_xticklabels(error_types_list, rotation=45, ha='right')\n",
    "    axes[2].set_ylabel('F1-Score')\n",
    "    axes[2].set_title('F1-Score por Tipo de Erro')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/output/notebooks/treinamento_sinkt/metrics_by_error_type.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Gráficos de métricas por tipo de erro salvos\")\n",
    "else:\n",
    "    print(\"❌ Dados insuficientes para análise por tipo de erro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados salvos:\n",
      "  - Modelo: data/output/notebooks/treinamento_sinkt/sinkt_model.pt\n",
      "  - Resumo: data/output/notebooks/treinamento_sinkt/training_results.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/output/notebooks/treinamento_sinkt', exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state if best_model_state is not None else model.state_dict(),\n",
    "    'config': config,\n",
    "    'test_metrics': test_metrics,\n",
    "    'history': history\n",
    "}, 'data/output/notebooks/treinamento_sinkt/sinkt_model.pt')\n",
    "\n",
    "results_summary = {\n",
    "    'metadata': {\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'model': 'SINKT',\n",
    "        'num_epochs_trained': len(history['train_loss']),\n",
    "        'best_val_auc': best_val_auc,\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'config': config,\n",
    "    'data_split': {\n",
    "        'train_students': len(train_ids),\n",
    "        'val_students': len(val_ids),\n",
    "        'test_students': len(test_ids),\n",
    "        'train_sequences': len(train_dataset),\n",
    "        'val_sequences': len(val_dataset),\n",
    "        'test_sequences': len(test_dataset)\n",
    "    },\n",
    "    'test_metrics': {\n",
    "        'loss': float(test_metrics['loss']),\n",
    "        'auc': float(test_metrics['auc']),\n",
    "        'accuracy': float(test_metrics['acc']),\n",
    "        'f1_score': float(test_metrics['f1']),\n",
    "        'precision': float(test_metrics['precision']),\n",
    "        'recall': float(test_metrics['recall'])\n",
    "    },\n",
    "    'training_history': {\n",
    "        'train_loss': [float(x) for x in history['train_loss']],\n",
    "        'val_loss': [float(x) for x in history['val_loss']],\n",
    "        'val_auc': [float(x) for x in history['val_auc']],\n",
    "        'val_acc': [float(x) for x in history['val_acc']],\n",
    "        'val_f1': [float(x) for x in history['val_f1']]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('data/output/notebooks/treinamento_sinkt/training_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Resultados salvos:\")\n",
    "print(\"  - Modelo: data/output/notebooks/treinamento_sinkt/sinkt_model.pt\")\n",
    "print(\"  - Resumo: data/output/notebooks/treinamento_sinkt/training_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMO DO TREINAMENTO DO MODELO SINKT\n",
      "================================================================================\n",
      "\n",
      "DADOS:\n",
      "  - Conceitos: 251\n",
      "  - Questões: 15\n",
      "  - Estudantes (train/val/test): 70/15/15\n",
      "  - Interações totais: 4499\n",
      "\n",
      "ARQUITETURA:\n",
      "  - TIEnc: Sentence-BERT (sentence-transformers/all-MiniLM-L6-v2)\n",
      "  - SIEnc: GAT com 2 camadas e 4 heads\n",
      "  - Student Encoder: GRU com 2 camadas\n",
      "  - Hidden dim: 128\n",
      "  - Parâmetros treináveis: 504,065\n",
      "\n",
      "TREINAMENTO:\n",
      "  - Épocas treinadas: 34\n",
      "  - Melhor AUC (validação): 0.7999\n",
      "  - Learning rate: 0.001\n",
      "  - Batch size: 32\n",
      "\n",
      "MÉTRICAS FINAIS (TESTE):\n",
      "  - AUC:       0.8218\n",
      "  - Accuracy:  0.7869\n",
      "  - F1-Score:  0.7360\n",
      "  - Precision: 0.6996\n",
      "  - Recall:    0.7763\n",
      "\n",
      "ARQUIVOS GERADOS:\n",
      "  - data/output/notebooks/treinamento_sinkt/sinkt_model.pt\n",
      "  - data/output/notebooks/treinamento_sinkt/training_results.json\n",
      "  - data/output/notebooks/treinamento_sinkt/training_results.png\n",
      "  - data/output/notebooks/treinamento_sinkt/confusion_matrix.png\n",
      "\n",
      "================================================================================\n",
      "✅ TREINAMENTO DO SINKT CONCLUÍDO COM SUCESSO!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMO DO TREINAMENTO DO MODELO SINKT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDADOS:\")\n",
    "print(f\"  - Conceitos: {len(concepts)}\")\n",
    "print(f\"  - Questões: {len(questions)}\")\n",
    "print(f\"  - Estudantes (train/val/test): {len(train_ids)}/{len(val_ids)}/{len(test_ids)}\")\n",
    "print(f\"  - Interações totais: {len(interactions)}\")\n",
    "\n",
    "print(f\"\\nARQUITETURA:\")\n",
    "print(f\"  - TIEnc: Sentence-BERT ({config['plm_model']})\")\n",
    "print(f\"  - SIEnc: GAT com {config['gat_layers']} camadas e {config['gat_heads']} heads\")\n",
    "print(f\"  - Student Encoder: GRU com {config['gru_layers']} camadas\")\n",
    "print(f\"  - Hidden dim: {config['hidden_dim']}\")\n",
    "print(f\"  - Parâmetros treináveis: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "print(f\"\\nTREINAMENTO:\")\n",
    "print(f\"  - Épocas treinadas: {len(history['train_loss'])}\")\n",
    "print(f\"  - Melhor AUC (validação): {best_val_auc:.4f}\")\n",
    "print(f\"  - Learning rate: {config['learning_rate']}\")\n",
    "print(f\"  - Batch size: {config['batch_size']}\")\n",
    "\n",
    "print(f\"\\nMÉTRICAS FINAIS (TESTE):\")\n",
    "print(f\"  - AUC:       {test_metrics['auc']:.4f}\")\n",
    "print(f\"  - Accuracy:  {test_metrics['acc']:.4f}\")\n",
    "print(f\"  - F1-Score:  {test_metrics['f1']:.4f}\")\n",
    "print(f\"  - Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  - Recall:    {test_metrics['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nARQUIVOS GERADOS:\")\n",
    "print(f\"  - data/output/notebooks/treinamento_sinkt/sinkt_model.pt\")\n",
    "print(f\"  - data/output/notebooks/treinamento_sinkt/training_results.json\")\n",
    "print(f\"  - data/output/notebooks/treinamento_sinkt/training_results.png\")\n",
    "print(f\"  - data/output/notebooks/treinamento_sinkt/confusion_matrix.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ TREINAMENTO DO SINKT CONCLUÍDO COM SUCESSO!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
