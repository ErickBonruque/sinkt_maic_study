{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Gera√ß√£o de Dados de Intera√ß√£o com LLM\n",
    "\n",
    "Este notebook implementa a **Etapa 3** do pipeline SINKT: gera√ß√£o de 3000-6000 intera√ß√µes simuladas usando LLM para respostas realistas.\n",
    "\n",
    "## Objetivo\n",
    "Gerar sequ√™ncias de intera√ß√µes realistas para cada estudante, incluindo respostas a quest√µes geradas por LLM.\n",
    "\n",
    "## Sa√≠da\n",
    "- `data/output/interactions.json`: Arquivo JSON contendo todas as intera√ß√µes simuladas com respostas realistas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI importado com sucesso\n",
      "‚úÖ Bibliotecas importadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Importar OpenAI\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    print(\"‚úÖ OpenAI importado com sucesso\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå OpenAI n√£o instalado. Instale com: pip install openai\")\n",
    "    raise\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar Cliente OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cliente OpenAI inicializado\n",
      "   Usando modelo: gpt-4.1-mini\n",
      "   API Key: Carregada de OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente OpenAI\n",
    "# A API key √© automaticamente lida de OPENAI_API_KEY\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"‚úÖ Cliente OpenAI inicializado\")\n",
    "print(\"   Usando modelo: gpt-4.1-mini\")\n",
    "print(\"   API Key: Carregada de OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados carregados:\n",
      "  - Perfis: 6\n",
      "  - Estudantes: 100\n",
      "  - Quest√µes: 680\n",
      "  - Conceitos: 251\n"
     ]
    }
   ],
   "source": [
    "# Carregar perfis\n",
    "with open('data/output/notebooks/geracao_perfis/profiles.json', 'r', encoding='utf-8') as f:\n",
    "    profiles_data = json.load(f)\n",
    "profiles = profiles_data['profiles']\n",
    "\n",
    "# Carregar estudantes\n",
    "with open('data/output/notebooks/geracao_estudantes/students.json', 'r', encoding='utf-8') as f:\n",
    "    students_data = json.load(f)\n",
    "students = students_data['students']\n",
    "\n",
    "# Carregar quest√µes\n",
    "with open('data/json/questions_graph.json', 'r', encoding='utf-8') as f:\n",
    "    questions_data = json.load(f)\n",
    "questions = questions_data.get('questions', [])\n",
    "\n",
    "# Carregar conceitos\n",
    "with open('data/json/concepts_graph.json', 'r', encoding='utf-8') as f:\n",
    "    concepts_data = json.load(f)\n",
    "concepts = concepts_data.get('concepts', [])\n",
    "\n",
    "print(f\"‚úÖ Dados carregados:\")\n",
    "print(f\"  - Perfis: {len(profiles)}\")\n",
    "print(f\"  - Estudantes: {len(students)}\")\n",
    "print(f\"  - Quest√µes: {len(questions)}\")\n",
    "print(f\"  - Conceitos: {len(concepts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configura√ß√£o de Par√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Configura√ß√µes:\n",
      "  - Intera√ß√µes por estudante: 30-60\n",
      "  - Modelo LLM: gpt-4.1-mini\n",
      "  - Temperatura: 0.7\n",
      "  - Checkpoint a cada: 10 estudantes\n",
      "  - Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes\n",
    "MIN_INTERACTIONS_PER_STUDENT = 30\n",
    "MAX_INTERACTIONS_PER_STUDENT = 60\n",
    "SEED = 42\n",
    "LLM_MODEL = \"gpt-4.1-mini\"\n",
    "LLM_TEMPERATURE = 0.7\n",
    "LLM_MAX_TOKENS = 200\n",
    "LLM_TIMEOUT = 10\n",
    "\n",
    "CHECKPOINT_INTERVAL = 10\n",
    "CHECKPOINT_FILE = 'data/output/interactions_checkpoint.json'\n",
    "\n",
    "ERROR_TYPES = [\n",
    "    'misconception',\n",
    "    'careless',\n",
    "    'slip',\n",
    "    'incomplete',\n",
    "    'misunderstanding'\n",
    "]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print(f\"üéØ Configura√ß√µes:\")\n",
    "print(f\"  - Intera√ß√µes por estudante: {MIN_INTERACTIONS_PER_STUDENT}-{MAX_INTERACTIONS_PER_STUDENT}\")\n",
    "print(f\"  - Modelo LLM: {LLM_MODEL}\")\n",
    "print(f\"  - Temperatura: {LLM_TEMPERATURE}\")\n",
    "print(f\"  - Checkpoint a cada: {CHECKPOINT_INTERVAL} estudantes\")\n",
    "print(f\"  - Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√µes de Gera√ß√£o com LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fun√ß√µes de gera√ß√£o definidas\n"
     ]
    }
   ],
   "source": [
    "def generate_response_with_llm(question: Dict, is_correct: bool, attempt: int = 1) -> str:\n",
    "    \"\"\"Gera resposta realista usando OpenAI LLM.\n",
    "    \n",
    "    Args:\n",
    "        question: Dicion√°rio com dados da quest√£o\n",
    "        is_correct: Se a resposta deve estar correta ou incorreta\n",
    "        attempt: N√∫mero da tentativa (para retry)\n",
    "    \n",
    "    Returns:\n",
    "        String com a resposta gerada\n",
    "    \"\"\"\n",
    "    \n",
    "    question_text = question.get('q', 'Quest√£o desconhecida')\n",
    "    question_type = question.get('type', 'descriptive')\n",
    "    \n",
    "    if question_type == 'multiple_choice':\n",
    "        if is_correct:\n",
    "            correct_answer = question.get('ans', 'A')\n",
    "            return f\"Op√ß√£o {correct_answer}\"\n",
    "        else:\n",
    "            options = ['A', 'B', 'C', 'D']\n",
    "            correct = question.get('ans', 'A')\n",
    "            wrong_options = [o for o in options if o != correct]\n",
    "            return f\"Op√ß√£o {random.choice(wrong_options)}\"\n",
    "    \n",
    "    try:\n",
    "        if is_correct:\n",
    "            prompt = f\"\"\"Voc√™ √© um estudante de Linux que entendeu bem o conceito. \n",
    "            Responda de forma clara e concisa (2-3 frases) a seguinte quest√£o:\n",
    "            \n",
    "            {question_text}\n",
    "            \n",
    "            Responda como um estudante competente, sem ser muito formal.\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"Voc√™ √© um estudante de Linux que tem uma compreens√£o errada ou incompleta.\n",
    "            Responda de forma realista (2-3 frases) a seguinte quest√£o, mas cometendo um erro:\n",
    "            \n",
    "            {question_text}\n",
    "            \n",
    "            Seu erro pode ser: confundir conceitos, entendimento parcial, ou misconception.\n",
    "            Responda como um estudante que n√£o entendeu bem.\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Voc√™ √© um estudante respondendo quest√µes sobre Linux.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=LLM_TEMPERATURE,\n",
    "            max_tokens=LLM_MAX_TOKENS,\n",
    "            timeout=LLM_TIMEOUT\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao chamar LLM (tentativa {attempt}): {str(e)}\")\n",
    "        \n",
    "        if is_correct:\n",
    "            return \"[Resposta correta - LLM indispon√≠vel]\"\n",
    "        else:\n",
    "            return \"[Resposta incorreta - LLM indispon√≠vel]\"\n",
    "\n",
    "def calculate_response_probability(student_params: Dict, question_difficulty: float) -> float:\n",
    "    \"\"\"Calcula probabilidade de resposta correta baseada em BKT.\"\"\"\n",
    "    mastery = student_params.get('mastery_init_level', 0.5)\n",
    "    guess = student_params.get('guess', 0.15)\n",
    "    slip = student_params.get('slip', 0.1)\n",
    "    \n",
    "    adjusted_mastery = mastery * (1 - question_difficulty * 0.3)\n",
    "    prob = adjusted_mastery + (1 - adjusted_mastery) * guess - adjusted_mastery * slip\n",
    "    return max(0, min(1, prob))\n",
    "\n",
    "def generate_error_explanation(error_type: str, concept_name: str, student_profile: str) -> str:\n",
    "    \"\"\"Gera explica√ß√£o realista para o erro.\"\"\"\n",
    "    explanations = {\n",
    "        'misconception': f\"Estudante confundiu o conceito de '{concept_name}' com outro similar. Necess√°rio refor√ßo conceitual.\",\n",
    "        'careless': f\"Erro por descuido na execu√ß√£o. Estudante conhece '{concept_name}' mas n√£o prestou aten√ß√£o.\",\n",
    "        'slip': f\"Erro por distra√ß√£o. Estudante sabe '{concept_name}' mas cometeu erro de digita√ß√£o/l√≥gica.\",\n",
    "        'incomplete': f\"Resposta incompleta sobre '{concept_name}'. Faltaram detalhes importantes.\",\n",
    "        'misunderstanding': f\"Entendimento errado do enunciado relacionado a '{concept_name}'.\"\n",
    "    }\n",
    "    return explanations.get(error_type, \"Erro desconhecido\")\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera√ß√£o de Intera√ß√µes para Todos os Estudantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando gera√ß√£o de intera√ß√µes com LLM...\n",
      "   Total de estudantes: 100\n",
      "   Intera√ß√µes esperadas: 3000-6000\n",
      "   Salvamento autom√°tico a cada 10 estudantes\n",
      "\n",
      "  Processando estudante 1/100...\n",
      "  Processando estudante 10/100...\n",
      "  üíæ Checkpoint salvo: 10/100 estudantes (455 intera√ß√µes)\n",
      "  Processando estudante 20/100...\n",
      "  üíæ Checkpoint salvo: 20/100 estudantes (875 intera√ß√µes)\n",
      "  Processando estudante 30/100...\n",
      "  üíæ Checkpoint salvo: 30/100 estudantes (1310 intera√ß√µes)\n",
      "  Processando estudante 40/100...\n",
      "  üíæ Checkpoint salvo: 40/100 estudantes (1758 intera√ß√µes)\n",
      "  Processando estudante 50/100...\n",
      "  üíæ Checkpoint salvo: 50/100 estudantes (2178 intera√ß√µes)\n",
      "  Processando estudante 60/100...\n",
      "  üíæ Checkpoint salvo: 60/100 estudantes (2639 intera√ß√µes)\n",
      "  Processando estudante 70/100...\n",
      "  üíæ Checkpoint salvo: 70/100 estudantes (3114 intera√ß√µes)\n",
      "  Processando estudante 80/100...\n",
      "  üíæ Checkpoint salvo: 80/100 estudantes (3558 intera√ß√µes)\n",
      "  Processando estudante 90/100...\n",
      "  üíæ Checkpoint salvo: 90/100 estudantes (3974 intera√ß√µes)\n",
      "  Processando estudante 100/100...\n",
      "  üíæ Checkpoint salvo: 100/100 estudantes (4450 intera√ß√µes)\n",
      "  üíæ Checkpoint salvo: 100/100 estudantes (4450 intera√ß√µes)\n",
      "\n",
      "‚úÖ 4450 intera√ß√µes geradas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(interactions: List[Dict], student_idx: int, total_students: int):\n",
    "    \"\"\"Salva checkpoint incremental das intera√ß√µes.\"\"\"\n",
    "    checkpoint_data = {\n",
    "        \"checkpoint_info\": {\n",
    "            \"last_student_processed\": student_idx,\n",
    "            \"total_students\": total_students,\n",
    "            \"progress_percentage\": round((student_idx + 1) / total_students * 100, 2),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_interactions\": len(interactions)\n",
    "        },\n",
    "        \"interactions\": interactions\n",
    "    }\n",
    "    \n",
    "    with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"  üíæ Checkpoint salvo: {student_idx + 1}/{total_students} estudantes ({len(interactions)} intera√ß√µes)\")\n",
    "\n",
    "def load_checkpoint():\n",
    "    \"\"\"Carrega checkpoint se existir.\"\"\"\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return data['interactions'], data['checkpoint_info']['last_student_processed']\n",
    "    return [], -1\n",
    "\n",
    "def generate_interactions(students: List, profiles: Dict, questions: List,\n",
    "                         min_interactions: int, max_interactions: int,\n",
    "                         seed: int, resume: bool = True) -> List[Dict]:\n",
    "    \"\"\"Gera intera√ß√µes para todos os estudantes com respostas via LLM e salvamento incremental.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    interactions = []\n",
    "    interaction_id = 0\n",
    "    start_idx = 0\n",
    "    \n",
    "    if resume:\n",
    "        interactions, last_processed = load_checkpoint()\n",
    "        if last_processed >= 0:\n",
    "            start_idx = last_processed + 1\n",
    "            interaction_id = len(interactions)\n",
    "            print(f\"üìÇ Checkpoint encontrado! Retomando do estudante {start_idx + 1}\")\n",
    "            print(f\"   Intera√ß√µes j√° processadas: {len(interactions)}\")\n",
    "    \n",
    "    total_students = len(students)\n",
    "    \n",
    "    for student_idx in range(start_idx, total_students):\n",
    "        student = students[student_idx]\n",
    "        \n",
    "        if (student_idx + 1) % 10 == 0 or student_idx == start_idx:\n",
    "            print(f\"  Processando estudante {student_idx + 1}/{total_students}...\")\n",
    "        \n",
    "        num_interactions = np.random.randint(min_interactions, max_interactions + 1)\n",
    "        \n",
    "        student_id = student['id']\n",
    "        profile_id = student['profile_id']\n",
    "        profile = profiles.get(profile_id, {})\n",
    "        \n",
    "        current_mastery = student.get('mastery_init_level', 0.5)\n",
    "        learn_rate = student.get('learn_rate', 0.03)\n",
    "        slip = student.get('slip', 0.1)\n",
    "        guess = student.get('guess', 0.15)\n",
    "        \n",
    "        student_params = {\n",
    "            'mastery_init_level': current_mastery,\n",
    "            'learn_rate': learn_rate,\n",
    "            'slip': slip,\n",
    "            'guess': guess\n",
    "        }\n",
    "        \n",
    "        for interaction_num in range(num_interactions):\n",
    "            if not questions:\n",
    "                continue\n",
    "            \n",
    "            question = random.choice(questions)\n",
    "            question_id = question.get('id', f'q_{interaction_num}')\n",
    "            question_type = question.get('type', 'multiple_choice')\n",
    "            question_difficulty = question.get('score', 2.5) / 5.0\n",
    "            concept_id = question.get('c_id', 'unknown')\n",
    "            concept_name = question.get('c_name', 'Conceito')\n",
    "            \n",
    "            correct_prob = calculate_response_probability(student_params, question_difficulty)\n",
    "            is_correct = np.random.random() < correct_prob\n",
    "            \n",
    "            response = generate_response_with_llm(question, is_correct)\n",
    "            \n",
    "            error_type = None\n",
    "            error_explanation = None\n",
    "            if not is_correct:\n",
    "                error_type = random.choice(ERROR_TYPES)\n",
    "                error_explanation = generate_error_explanation(\n",
    "                    error_type,\n",
    "                    concept_name,\n",
    "                    profile_id\n",
    "                )\n",
    "            \n",
    "            mastery_before = current_mastery\n",
    "            if is_correct:\n",
    "                current_mastery += (1 - current_mastery) * learn_rate\n",
    "            else:\n",
    "                current_mastery *= (1 - learn_rate * 0.5)\n",
    "            \n",
    "            interaction = {\n",
    "                'interaction_id': f'int_{interaction_id:06d}',\n",
    "                'student_id': student_id,\n",
    "                'question_id': question_id,\n",
    "                'concept_id': concept_id,\n",
    "                'question_type': question_type,\n",
    "                'timestamp': (datetime.now() - timedelta(days=num_interactions-interaction_num)).isoformat(),\n",
    "                'response': response,\n",
    "                'is_correct': is_correct,\n",
    "                'error_type': error_type,\n",
    "                'error_explanation': error_explanation,\n",
    "                'mastery_before': round(mastery_before, 4),\n",
    "                'mastery_after': round(current_mastery, 4),\n",
    "                'time_spent_seconds': np.random.randint(15, 300)\n",
    "            }\n",
    "            \n",
    "            interactions.append(interaction)\n",
    "            interaction_id += 1\n",
    "        \n",
    "        if (student_idx + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            save_checkpoint(interactions, student_idx, total_students)\n",
    "    \n",
    "    save_checkpoint(interactions, total_students - 1, total_students)\n",
    "    \n",
    "    return interactions\n",
    "\n",
    "print(\"üîÑ Iniciando gera√ß√£o de intera√ß√µes com LLM...\")\n",
    "print(f\"   Total de estudantes: {len(students)}\")\n",
    "print(f\"   Intera√ß√µes esperadas: {len(students) * MIN_INTERACTIONS_PER_STUDENT}-{len(students) * MAX_INTERACTIONS_PER_STUDENT}\")\n",
    "print(f\"   Salvamento autom√°tico a cada {CHECKPOINT_INTERVAL} estudantes\")\n",
    "print()\n",
    "\n",
    "interactions = generate_interactions(students, profiles, questions,\n",
    "                                    MIN_INTERACTIONS_PER_STUDENT,\n",
    "                                    MAX_INTERACTIONS_PER_STUDENT,\n",
    "                                    SEED,\n",
    "                                    resume=True)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(interactions)} intera√ß√µes geradas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise de Qualidade das Intera√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä An√°lise de Qualidade das Intera√ß√µes:\n",
      "\n",
      "  Estat√≠sticas Gerais:\n",
      "    - Total de intera√ß√µes: 4450\n",
      "    - Total de estudantes: 100\n",
      "    - M√©dia por estudante: 44.5\n",
      "    - Acur√°cia geral: 44.4%\n",
      "\n",
      "  Qualidade das Respostas:\n",
      "    - Respostas v√°lidas: 4450/4450\n",
      "    - Taxa de validade: 100.0%\n",
      "\n",
      "  Distribui√ß√£o de Erros:\n",
      "    - misconception: 490 (19.8%)\n",
      "    - slip: 513 (20.7%)\n",
      "    - careless: 462 (18.7%)\n",
      "    - misunderstanding: 513 (20.7%)\n",
      "    - incomplete: 497 (20.1%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_interactions_quality(interactions: List[Dict], students: List) -> Dict:\n",
    "    \"\"\"Analisa qualidade das intera√ß√µes geradas.\"\"\"\n",
    "    \n",
    "    total_interactions = len(interactions)\n",
    "    correct_interactions = sum(1 for i in interactions if i['is_correct'])\n",
    "    accuracy = correct_interactions / total_interactions if total_interactions > 0 else 0\n",
    "    \n",
    "    error_distribution = defaultdict(int)\n",
    "    for interaction in interactions:\n",
    "        if interaction['error_type']:\n",
    "            error_distribution[interaction['error_type']] += 1\n",
    "    \n",
    "    interactions_per_student = defaultdict(int)\n",
    "    for interaction in interactions:\n",
    "        interactions_per_student[interaction['student_id']] += 1\n",
    "    \n",
    "    empty_responses = sum(1 for i in interactions if not i['response'] or len(i['response'].strip()) == 0)\n",
    "    \n",
    "    return {\n",
    "        'total_interactions': total_interactions,\n",
    "        'total_students': len(students),\n",
    "        'avg_interactions_per_student': total_interactions / len(students) if students else 0,\n",
    "        'correct_interactions': correct_interactions,\n",
    "        'accuracy': accuracy,\n",
    "        'error_distribution': dict(error_distribution),\n",
    "        'interactions_per_student_stats': {\n",
    "            'min': min(interactions_per_student.values()) if interactions_per_student else 0,\n",
    "            'max': max(interactions_per_student.values()) if interactions_per_student else 0,\n",
    "            'mean': np.mean(list(interactions_per_student.values())) if interactions_per_student else 0\n",
    "        },\n",
    "        'response_quality': {\n",
    "            'total_responses': total_interactions,\n",
    "            'empty_responses': empty_responses,\n",
    "            'valid_responses': total_interactions - empty_responses,\n",
    "            'validity_percentage': ((total_interactions - empty_responses) / total_interactions * 100) if total_interactions > 0 else 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "quality_analysis = analyze_interactions_quality(interactions, students)\n",
    "\n",
    "print(\"\\nüìä An√°lise de Qualidade das Intera√ß√µes:\")\n",
    "print(f\"\\n  Estat√≠sticas Gerais:\")\n",
    "print(f\"    - Total de intera√ß√µes: {quality_analysis['total_interactions']}\")\n",
    "print(f\"    - Total de estudantes: {quality_analysis['total_students']}\")\n",
    "print(f\"    - M√©dia por estudante: {quality_analysis['avg_interactions_per_student']:.1f}\")\n",
    "print(f\"    - Acur√°cia geral: {quality_analysis['accuracy']:.1%}\")\n",
    "print(f\"\\n  Qualidade das Respostas:\")\n",
    "print(f\"    - Respostas v√°lidas: {quality_analysis['response_quality']['valid_responses']}/{quality_analysis['response_quality']['total_responses']}\")\n",
    "print(f\"    - Taxa de validade: {quality_analysis['response_quality']['validity_percentage']:.1f}%\")\n",
    "print(f\"\\n  Distribui√ß√£o de Erros:\")\n",
    "for error_type, count in quality_analysis['error_distribution'].items():\n",
    "    pct = (count / (quality_analysis['total_interactions'] - quality_analysis['correct_interactions'])) * 100\n",
    "    print(f\"    - {error_type}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvamento das Intera√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Checkpoint removido (processamento completo)\n",
      "\n",
      "‚úÖ Intera√ß√µes salvas em: data/output/interactions.json\n",
      "üì¶ Total de intera√ß√µes: 4450\n",
      "üíæ Tamanho do arquivo: 2.61 MB\n"
     ]
    }
   ],
   "source": [
    "# Criar estrutura completa com metadados\n",
    "output_data = {\n",
    "    \"metadata\": {\n",
    "        \"description\": \"Conjunto de intera√ß√µes simuladas com respostas geradas por LLM para estudantes SINKT\",\n",
    "        \"version\": \"2.0.0\",\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"llm_model\": LLM_MODEL,\n",
    "        \"llm_temperature\": LLM_TEMPERATURE,\n",
    "        \"total_interactions\": len(interactions),\n",
    "        \"total_students\": len(students),\n",
    "        \"avg_interactions_per_student\": quality_analysis['avg_interactions_per_student'],\n",
    "        \"accuracy\": quality_analysis['accuracy'],\n",
    "        \"error_types\": ERROR_TYPES,\n",
    "        \"quality_metrics\": quality_analysis\n",
    "    },\n",
    "    \"interactions\": interactions\n",
    "}\n",
    "\n",
    "output_file = 'data/output/interactions.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    os.remove(CHECKPOINT_FILE)\n",
    "    print(f\"üóëÔ∏è  Checkpoint removido (processamento completo)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Intera√ß√µes salvas em: {output_file}\")\n",
    "print(f\"üì¶ Total de intera√ß√µes: {len(interactions)}\")\n",
    "print(f\"üíæ Tamanho do arquivo: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplos de Intera√ß√µes Geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Exemplos de Intera√ß√µes Geradas:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Exemplo 1:\n",
      "  ID: int_000000\n",
      "  Estudante: student_0000\n",
      "  Quest√£o: concept_262_q4\n",
      "  Tipo: descriptive\n",
      "  Resposta: A Hierarquia de Diret√≥rios √© uma lista dos arquivos que est√£o instalados no sistema, e a Estrutura d...\n",
      "  Correta: ‚úó N√ÉO\n",
      "  Tipo de Erro: misconception\n",
      "  Explica√ß√£o: Estudante confundiu o conceito de 'Hierarquia de Diret√≥rios' com outro similar. Necess√°rio refor√ßo conceitual.\n",
      "  Dom√≠nio Antes: 0.529\n",
      "  Dom√≠nio Depois: 0.519\n",
      "  Tempo: 285s\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Exemplo 2:\n",
      "  ID: int_000001\n",
      "  Estudante: student_0000\n",
      "  Quest√£o: concept_008_q1\n",
      "  Tipo: multiple_choice\n",
      "  Resposta: Op√ß√£o D\n",
      "  Correta: ‚úó N√ÉO\n",
      "  Tipo de Erro: slip\n",
      "  Explica√ß√£o: Erro por distra√ß√£o. Estudante sabe '-C' mas cometeu erro de digita√ß√£o/l√≥gica.\n",
      "  Dom√≠nio Antes: 0.519\n",
      "  Dom√≠nio Depois: 0.508\n",
      "  Tempo: 203s\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Exemplo 3:\n",
      "  ID: int_000002\n",
      "  Estudante: student_0000\n",
      "  Quest√£o: concept_097_q3\n",
      "  Tipo: multiple_choice\n",
      "  Resposta: Op√ß√£o B\n",
      "  Correta: ‚úó N√ÉO\n",
      "  Tipo de Erro: careless\n",
      "  Explica√ß√£o: Erro por descuido na execu√ß√£o. Estudante conhece 'fc' mas n√£o prestou aten√ß√£o.\n",
      "  Dom√≠nio Antes: 0.508\n",
      "  Dom√≠nio Depois: 0.498\n",
      "  Tempo: 136s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìã Exemplos de Intera√ß√µes Geradas:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Mostrar 3 exemplos\n",
    "for i, interaction in enumerate(interactions[:3]):\n",
    "    print(f\"\\nExemplo {i+1}:\")\n",
    "    print(f\"  ID: {interaction['interaction_id']}\")\n",
    "    print(f\"  Estudante: {interaction['student_id']}\")\n",
    "    print(f\"  Quest√£o: {interaction['question_id']}\")\n",
    "    print(f\"  Tipo: {interaction['question_type']}\")\n",
    "    print(f\"  Resposta: {interaction['response'][:100]}...\" if len(interaction['response']) > 100 else f\"  Resposta: {interaction['response']}\")\n",
    "    print(f\"  Correta: {'‚úì SIM' if interaction['is_correct'] else '‚úó N√ÉO'}\")\n",
    "    if interaction['error_type']:\n",
    "        print(f\"  Tipo de Erro: {interaction['error_type']}\")\n",
    "        print(f\"  Explica√ß√£o: {interaction['error_explanation']}\")\n",
    "    print(f\"  Dom√≠nio Antes: {interaction['mastery_before']:.3f}\")\n",
    "    print(f\"  Dom√≠nio Depois: {interaction['mastery_after']:.3f}\")\n",
    "    print(f\"  Tempo: {interaction['time_spent_seconds']}s\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo da Execu√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ GERA√á√ÉO DE INTERA√á√ïES COM LLM CONCLU√çDA COM SUCESSO!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Arquivo gerado:\n",
      "  - data/output/interactions.json\n",
      "\n",
      "üìä Resumo:\n",
      "  - Total de intera√ß√µes: 4450\n",
      "  - Estudantes: 100\n",
      "  - M√©dia por estudante: 44.5\n",
      "  - Acur√°cia: 44.4%\n",
      "  - Modelo LLM: gpt-4.1-mini\n",
      "  - Respostas v√°lidas: 100.0%\n",
      "\n",
      "‚úÖ Pr√≥ximo passo: Execute o notebook '04_analise_metricas.ipynb'\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ GERA√á√ÉO DE INTERA√á√ïES COM LLM CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Arquivo gerado:\")\n",
    "print(f\"  - {output_file}\")\n",
    "print(f\"\\nüìä Resumo:\")\n",
    "print(f\"  - Total de intera√ß√µes: {len(interactions)}\")\n",
    "print(f\"  - Estudantes: {len(students)}\")\n",
    "print(f\"  - M√©dia por estudante: {quality_analysis['avg_interactions_per_student']:.1f}\")\n",
    "print(f\"  - Acur√°cia: {quality_analysis['accuracy']:.1%}\")\n",
    "print(f\"  - Modelo LLM: {LLM_MODEL}\")\n",
    "print(f\"  - Respostas v√°lidas: {quality_analysis['response_quality']['validity_percentage']:.1f}%\")\n",
    "print(f\"\\n‚úÖ Pr√≥ximo passo: Execute o notebook '04_analise_metricas.ipynb'\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
