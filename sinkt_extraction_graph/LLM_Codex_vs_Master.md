# Guia Definitivo: Pipeline de Engenharia de Conhecimento SINKT (Codex vs Master)

Este documento detalha o funcionamento tÃ©cnico, os prompts literais e a lÃ³gica de execuÃ§Ã£o dos dois pipelines.

## Resumo Executivo

**Ambas as versÃµes compartilham 75% do pipeline (Fases 1-3). A diferenÃ§a estÃ¡ na Fase 4:**

| Aspecto | CODEX | MASTER |
|---------|-------|--------|
| **Arquitetura Fase 4** | Multi-Agente Real (LangGraph) | Mega-Prompt (Role-Playing) |
| **NÃºmero de Agentes** | 4 agentes sequenciais | 8 personas simuladas |
| **Calls de API/Aresta** | 4 chamadas separadas | 1 chamada (batch de 15) |
| **Resultado Final** | 260 arestas (alta densidade) | 174 arestas (alta precisÃ£o) |
| **Custo** | ~60x mais caro | Mais eficiente |
| **Auditabilidade** | Log detalhado por agente | Debate interno opaco |

## Diagrama de Fluxo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASE 1-2: PIPELINE COMUM                      â”‚
â”‚                     (IdÃªntico em ambos)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ExtraÃ§Ã£o â†’ gpt-4o-mini (26 capÃ­tulos paralelos)              â”‚
â”‚    â†“ ~360 conceitos brutos                                       â”‚
â”‚ 2. InduÃ§Ã£o Ontologia â†’ gpt-4o (taxonomia canÃ´nica)              â”‚
â”‚    â†“ ~254 conceitos limpos                                       â”‚
â”‚ 3. ExtraÃ§Ã£o RelaÃ§Ãµes â†’ gpt-4o-mini (capÃ­tulo a capÃ­tulo)        â”‚
â”‚    â†“ ~254 relaÃ§Ãµes iniciais                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FASE 3: DENSIFICAÃ‡ÃƒO HÃBRIDA                    â”‚
â”‚                     (IdÃªntico em ambos)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Cleaner â†’ gpt-4o-mini (remove ruÃ­dos)                        â”‚
â”‚ 2. Architect â†’ text-embedding-3-small + gpt-4o-mini             â”‚
â”‚    (similaridade vetorial + validaÃ§Ã£o semÃ¢ntica)                 â”‚
â”‚ 3. Teacher â†’ gpt-4o-mini (promove PREREQUISITE)                 â”‚
â”‚    â†“ +12-18 novas arestas                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CODEX (Swarm)   â”‚                    â”‚  MASTER (Oracle)     â”‚
â”‚  FASE 4          â”‚                    â”‚  FASE 4              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LangGraph:       â”‚                    â”‚ Mega-Prompt:         â”‚
â”‚ â€¢ Cleaner        â”‚                    â”‚ â€¢ 8 Personas         â”‚
â”‚ â€¢ Expert         â”‚                    â”‚   Simuladas          â”‚
â”‚ â€¢ Analyst        â”‚                    â”‚ â€¢ 1 Call/15 arestas  â”‚
â”‚ â€¢ Judge          â”‚                    â”‚                      â”‚
â”‚                  â”‚                    â”‚                      â”‚
â”‚ 4 calls/aresta   â”‚                    â”‚ Batch Processing     â”‚
â”‚ ~252 candidatos  â”‚                    â”‚ ~261 candidatos      â”‚
â”‚ â†“                â”‚                    â”‚ â†“                    â”‚
â”‚ 260 arestas âœ“    â”‚                    â”‚ 174 arestas âœ“        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Fase 1 e 2: O Pipeline Comum (Alicerce)
*(IdÃªntico em ambas as versÃµes)*

### 1. ExtraÃ§Ã£o de Conceitos (Concept Extraction)
*   **Modelo:** `gpt-4o-mini` (ChatOpenAI)
*   **ExecuÃ§Ã£o:** Paralela (3 workers) em todos os 26 capÃ­tulos do livro
*   **Prompt de Sistema:**
    ```text
    VocÃª Ã© um Especialista em Knowledge Tracing e Engenharia de Dados.
    Sua tarefa Ã© extrair conceitos tÃ©cnicos (Knowledge Components) de material didÃ¡tico sobre Linux.
    ### DIRETRIZES DE FILTRAGEM (NEGATIVE CONSTRAINTS):
    Para reduzir ruÃ­do, vocÃª deve **IGNORAR** ativamente:
    1. VariÃ¡veis e Placeholders ($VAR, <param>).
    2. Metadados Editoriais (CapÃ­tulo X, PÃ¡gina Y).
    3. Termos GenÃ©ricos (apenas termos tÃ©cnicos vÃ¡lidos).
    ```
*   **Resultado:** ~360 conceitos brutos extraÃ­dos (Master) / ~333 (Codex)

### 2. InduÃ§Ã£o de Ontologia (Ontology Induction)
*   **Modelo:** `gpt-4o` (ChatOpenAI)
*   **FunÃ§Ã£o:** Criar taxonomia canÃ´nica a partir dos tipos brutos extraÃ­dos
*   **Prompt:**
    ```text
    Analise os tipos brutos e mapeie para categorias mestras:
    COMANDO, SISTEMA_ARQUIVOS, REDE, CONCEITO_TEORICO, FERRAMENTA, HARDWARE, SHELL_SCRIPT, NOISE
    Mapeie ruÃ­dos (metadados, OCR) para categoria especial 'NOISE'.
    ```
*   **Resultado:** ~140 tipos brutos â†’ 7 categorias canÃ´nicas + NOISE

### 3. NormalizaÃ§Ã£o e ConsolidaÃ§Ã£o
*   **Processo:** Aplicar mapa ontolÃ³gico, filtrar NOISE, deduplicar por nome
*   **Resultado:** ~254 conceitos Ãºnicos consolidados (Master) / ~216 (Codex)

### 4. ExtraÃ§Ã£o de RelaÃ§Ãµes (Relation Extraction)
*   **Modelo:** `gpt-4o-mini` (ChatOpenAI)
*   **ExecuÃ§Ã£o:** Paralela (3 workers) capÃ­tulo a capÃ­tulo
*   **Prompt de UsuÃ¡rio:**
    ```text
    Analise o texto do CapÃ­tulo {chapter_id} e a lista de conceitos presentes nele.
    Lista de Conceitos VÃ¡lidos (NÃ³s): {concept_list}
    Identifique as relaÃ§Ãµes semÃ¢nticas (IS_A, PART_OF, USE, PREREQUISITE, RELATED_TO)
    explÃ­citas ou implÃ­citas entre esses conceitos.
    ```
*   **Resultado:** ~254 relaÃ§Ãµes extraÃ­das (Master) / ~212 (Codex)

---

## A BifurcaÃ§Ã£o: EstratÃ©gias de ValidaÃ§Ã£o

Aqui detalhamos a "caixa preta" de cada abordagem.

### CODEX: The Council Swarm (Busca Ativa Multi-Agente)

O Codex utiliza o **LangGraph** para orquestrar agentes autÃ´nomos que votam em cada aresta candidata.

#### Fase 3: DensificaÃ§Ã£o HÃ­brida (3 Agentes)

**Pipeline:**
1. **The Cleaner** â†’ 2. **The Architect (HÃ­brido)** â†’ 3. **The Teacher**

##### Agente 1: The Cleaner (Triagem RÃ¡pida)
*   **Modelo:** `gpt-4o-mini` (via get_model("gpt-4o-mini")) (ChatOpenAI, llm_mini)
*   **FunÃ§Ã£o:** Remover conceitos-ruÃ­do antes de gerar embeddings
*   **ExecuÃ§Ã£o:** Batches de 150 conceitos
*   **Resultado:** Remove ~17-28 ruÃ­dos (variÃ¡veis soltas, erros OCR)

##### Agente 2: The Architect (Arquiteto HÃ­brido)
**Parte 1 - Scout (MatemÃ¡tica Pura):**
*   **Modelo:** `text-embedding-3-small` (OpenAIEmbeddings, embeddings_model) (OpenAI Embeddings)
    *   **FunÃ§Ã£o:** Gerar embeddings e calcular similaridade de cosseno
    *   **Threshold:** 0.82 (permissivo)
    *   **Top-K:** 8 vizinhos mais similares por nÃ³
    *   **Resultado:** ~14-26 candidatos matemÃ¡ticos
*   **Parte 2 - Validator (ValidaÃ§Ã£o SemÃ¢ntica):**
*   **Modelo:** `gpt-4o-mini` (ChatOpenAI, llm_mini)
    *   **FunÃ§Ã£o:** Validar semanticamente os candidatos
    *   **Batches:** 20 pares por chamada
    *   **DecisÃ£o:** RELATED_TO, USE ou SKIP
    *   **Resultado:** ~12-18 conexÃµes validadas

##### Agente 3: The Teacher (Pedagogo)
*   **Modelo:** `gpt-4o-mini` (ChatOpenAI, llm_mini)
*   **FunÃ§Ã£o:** Promover relaÃ§Ãµes para PREREQUISITE quando hÃ¡ dependÃªncia de aprendizado
*   **Batches:** 50 relaÃ§Ãµes
*   **Resultado:** ~2-5 relaÃ§Ãµes promovidas para PREREQUISITE

#### Fase 4: ValidaÃ§Ã£o Final Multi-Agente (LangGraph - 4 Agentes)

**Fluxo do LangGraph:**
`Cleaner` â†’ `Expert` â†’ `Analyst` â†’ `Judge`

**GeraÃ§Ã£o de Candidatos (Scout & Bridge):**
*   **Scout:** Similaridade > 0.75 (Top 350 candidatos)
*   **Bridge (Anti-Ilha):** Conceitos de capÃ­tulos distantes (>3 caps) com similaridade > 0.70 (Top 150)
*   **Total:** ~252-500 candidatos para validaÃ§Ã£o

##### Agente 1: The Cleaner (O Porteiro)
*   **Modelo:** `gpt-4o-mini` (via get_model("gpt-4o-mini")) (ChatOpenAI, llm_mini)
*   **FunÃ§Ã£o:** Triagem rÃ¡pida - eliminar lixo Ã³bvio antes dos modelos caros
*   **ExecuÃ§Ã£o:** Primeira etapa do fluxo (early rejection)
*   **Prompt:**
    ```text
    VocÃª Ã© o CLEANER do grafo de conhecimento.
    Analise a aresta: {source} ({source_type}) -> {target} ({target_type}) [Score: {score}]
    
    CRITÃ‰RIOS DE ELIMINAÃ‡ÃƒO IMEDIATA (Vote REJECT):
    1. AlucinaÃ§Ãµes (conceitos inexistentes no contexto Linux)
    2. Tipos Errados (variÃ¡veis soltas conectadas a conceitos teÃ³ricos)
    3. Meta-dados (artefatos do livro: Figura, Tabela, PÃ¡gina)
    
    Se minimamente plausÃ­vel, vote ABSTAIN.
    ```
*   **DecisÃ£o:** REJECT ou ABSTAIN
*   **OtimizaÃ§Ã£o:** Se REJECT, pula Expert e Analyst (economia de tokens)

##### Agente 2: The Expert (Validador TÃ©cnico e PedagÃ³gico)
*   **Modelo:** `gpt-4o` (via get_model("gpt-4o"))
*   **FunÃ§Ã£o:** ValidaÃ§Ã£o tÃ©cnica e pedagÃ³gica profunda
*   **Prompt:**
    ```text
    VocÃª Ã© o ESPECIALISTA SÃŠNIOR (Engenheiro Linux + Pedagogo).
    Analise: {source} -> {target}
    
    MISSÃƒO 1 - ValidaÃ§Ã£o TÃ©cnica:
    - A relaÃ§Ã£o Ã© tecnicamente verdadeira?
    
    MISSÃƒO 2 - ValidaÃ§Ã£o PedagÃ³gica:
    - Aprender A desbloqueia B? â†’ MODIFY: PREREQUISITE
    - A Ã© ferramenta de B? â†’ MODIFY: USE
    - A compÃµe B? â†’ MODIFY: PART_OF
    - Apenas relacionado? â†’ APPROVE: RELATED_TO
    ```
*   **DecisÃ£o:** APPROVE, REJECT, MODIFY (com tipo sugerido)

##### Agente 3: The Analyst (Arquiteto Estrutural)
*   **Modelo:** `gpt-4o` (via get_model("gpt-4o"))
*   **FunÃ§Ã£o:** ConsistÃªncia estrutural e ontolÃ³gica
*   **Prompt:**
    ```text
    VocÃª Ã© o ANALISTA ESTRUTURAL.
    Analise: {source} ({source_type}) -> {target} ({target_type})
    
    CHECAGENS:
    1. Hierarquia de Tipos: 'Conceito Abstrato' nÃ£o pode ser PART_OF 'Comando'
    2. Topologia: DireÃ§Ã£o da seta faz sentido? (Geral â†’ EspecÃ­fico)
    3. PrevenÃ§Ã£o de Ciclos: RelaÃ§Ã£o cria ciclo lÃ³gico?
    ```
*   **DecisÃ£o:** APPROVE ou REJECT

##### Agente 4: The Judge (Decisor Final)
*   **Modelo:** `gpt-4o` (via get_model("gpt-4o"))
*   **FunÃ§Ã£o:** Sintetizar votos e emitir veredito final
*   **Input:** DossiÃª completo com votos de Cleaner, Expert e Analyst
*   **Prompt:**
    ```text
    VocÃª Ã© o JUIZ SUPREMO do grafo SINKT.
    Decida: {source} -> {target}
    
    VOTOS DO CONSELHO:
    {votes}
    
    REGRAS:
    1. Veto TÃ©cnico: Se Expert ou Cleaner rejeitou â†’ DISCARD
    2. TipificaÃ§Ã£o: Priorize tipo sugerido pelo Expert
    3. SeguranÃ§a: Na dÃºvida â†’ DISCARD
    ```
*   **Output:** KEEP ou DISCARD + tipo final + justificativa
*   **Resultado:** ~53 arestas aprovadas de ~252 candidatos

**ğŸ“‹ Modelos Declarados no CÃ³digo:**
```python
MODELS = {
    "scout_embed": OpenAIEmbeddings(model="text-embedding-3-small"),
    "cleaner": get_model("gpt-4o-mini"),
    "expert": get_model("gpt-4o"),
    "analyst": get_model("gpt-4o"),
    "judge": get_model("gpt-4o"),
}
```

---

### MASTER: The SINKT Oracle (Auditoria Unificada)

O Master nÃ£o usa mÃºltiplos agentes chamando API separadamente. Ele usa um **Mega-Prompt (Role-Playing)** onde uma Ãºnica chamada simula uma mesa redonda completa.

#### Fase 3: DensificaÃ§Ã£o HÃ­brida (3 Agentes - IdÃªntico ao Codex)

**Pipeline:** Cleaner â†’ Architect (Embeddings + Validator) â†’ Teacher

*Mesma estrutura do Codex, com pequenas diferenÃ§as nos resultados:*
*   **Cleaner:** Remove ~28 ruÃ­dos (vs ~17 no Codex)
*   **Architect:** ~14 candidatos matemÃ¡ticos â†’ ~12 validados
*   **Teacher:** ~2 promovidos para PREREQUISITE
*   **Resultado:** 226 nÃ³s, 220 arestas (densidade: 0.00433)

#### Fase 4: ValidaÃ§Ã£o Final - O Oracle (Mesa Redonda Virtual)

*   **Modelo Declarado:** `gpt-5.1` (ChatOpenAI, llm_judge)
*   **Processamento:** Batches de 15 arestas por chamada
*   **Arquitetura:** Mega-Prompt simulando 8 personas em debate interno

**ğŸ“‹ CÃ³digo:**
```python
llm_judge = ChatOpenAI(model="gpt-5.1", temperature=0)
```

##### As 8 Personas da Mesa Redonda:

1.  **Professor (Pedagogo):** Foca na Causalidade PedagÃ³gica
    *   "Aprender A desbloqueia B?"
    *   Valida dependÃªncias de aprendizado

2.  **Engenheiro (TÃ©cnico):** Foca na Verdade TÃ©cnica
    *   "'ls' realmente lista arquivos?"
    *   Valida precisÃ£o factual Linux

3.  **Otimizador (Anti-RedundÃ¢ncia):** CaÃ§a Duplicatas
    *   "Se Aâ†’B e Bâ†’C, precisamos de Aâ†’C?"
    *   Remove transitividades desnecessÃ¡rias

4.  **CÃ©tico (Anti-AlucinaÃ§Ã£o):** CaÃ§a Conceitos Falsos
    *   "'Linux' Ã© um 'Comando'? NÃ£o!"
    *   Detecta erros de extraÃ§Ã£o

5.  **TopÃ³logo (Protetor de DAG):** Evita Ciclos
    *   "A depende de B, B nÃ£o pode depender de A"
    *   Garante hierarquia Geral â†’ EspecÃ­fico

6.  **Terminologista (Padronizador):** Unifica Tipos
    *   "Use PREREQUISITE apenas para bloqueios de aprendizado"
    *   Aplica taxonomia canÃ´nica

7.  **Reparador (Salvacionista):** Tenta Corrigir
    *   "DireÃ§Ã£o errada? Inverta!"
    *   "Tipo fraco? FortaleÃ§a!"
    *   PropÃµe REFACTOR em vez de DISCARD

8.  **JUIZ (Decisor):** Sintetiza e Bate o Martelo
    *   Pondera votos das 7 personas
    *   Emite veredito final

##### Regras de DecisÃ£o do Oracle:

*   **KEEP:** Tecnicamente verdadeira + pedagogicamente Ãºtil + topologicamente segura
*   **REFACTOR:**
    *   Erro de DireÃ§Ã£o: "Shell PART_OF Bash" â†’ Inverter para "Bash IS_A Shell"
    *   Erro de Tipo: "ls PREREQUISITE Terminal" â†’ Mudar para "Terminal USE ls"
*   **DISCARD:**
    *   AlucinaÃ§Ãµes (fatos falsos)
    *   ConexÃµes genÃ©ricas ("Linux RELATED_TO Computador")
    *   Ciclos Ã³bvios

##### Tipos CanÃ´nicos Permitidos:
1.  **PREREQUISITE:** DependÃªncia de aprendizado (A antes de B)
2.  **PART_OF:** ComposiÃ§Ã£o (A Ã© componente de B)
3.  **IS_A:** Taxonomia (A Ã© tipo de B)
4.  **USE:** Funcional (A utiliza B)
5.  **RELATED_TO:** AssociaÃ§Ã£o genÃ©rica (Ãºltimo recurso)

##### Resultado da ValidaÃ§Ã£o:
*   **Input:** 261 relaÃ§Ãµes para auditar
*   **Aprovadas:** 208 (KEEP + REFACTOR)
*   **Descartadas:** 38
*   **Refatoradas:** 134 (mudanÃ§a de tipo ou direÃ§Ã£o)
*   **Output Final:** 226 nÃ³s, 174 arestas (densidade: 0.00342)

---

## Comparativo TÃ©cnico Final

Esta tabela resume os resultados obtidos na Ãºltima execuÃ§Ã£o de cada pipeline.

| MÃ©trica / Recurso | **CODEX (Swarm)** | **MASTER (Oracle)** | **AnÃ¡lise** |
| :--- | :--- | :--- | :--- |
| **Pipeline Completo** | 4 Fases (Extraction â†’ Ontology â†’ Relations â†’ Densification â†’ Multi-Agent Council) | 4 Fases (Extraction â†’ Ontology â†’ Relations â†’ Densification â†’ Oracle Audit) | Estrutura idÃªntica, diferenÃ§a na Fase 4. |
| **Fase 1-2 (Comum)** | gpt-4o-mini (Extraction) + gpt-4o (Ontology) | gpt-4o-mini (Extraction) + gpt-4o (Ontology) | IdÃªntico em ambas versÃµes. |
| **Fase 3 (DensificaÃ§Ã£o)** | 3 Agentes: Cleaner + Architect (Embeddings + gpt-4o-mini) + Teacher | 3 Agentes: Cleaner + Architect (Embeddings + gpt-4o-mini) + Teacher | IdÃªntico em ambas versÃµes. |
| **Fase 4 (ValidaÃ§Ã£o)** | **LangGraph Multi-Agent:** 4 agentes sequenciais (Cleaner â†’ Expert â†’ Analyst â†’ Judge) | **Mega-Prompt Oracle:** 8 personas simuladas em 1 chamada | **DiferenÃ§a-chave:** Codex = 4 calls/aresta; Master = 1 call/15 arestas. |
| **Total de NÃ³s** | **216** | **226** | Master manteve mais nÃ³s (Cleaner menos agressivo). |
| **Total de Arestas** | **260** ğŸ“ˆ | **174** ğŸ“‰ | Codex expandiu (+49%) vs Master reduziu (-21%). |
| **Densidade do Grafo** | **0.0056** (Alta) | **0.0034** (Baixa) | Codex oferece mais caminhos para Knowledge Tracing. |
| **NÃ³s Ã“rfÃ£os** | **0** (Zero) | **0** (Removidos) | Ambos resolveram o problema de "ilhas". |
| **Ciclos (Loops)** | NÃ£o medido | **19** | Master reportou ciclos residuais. |
| **Custo Computacional** | ğŸ”´ **Alto** (4 LLM calls/aresta + embeddings) | ğŸŸ¢ **MÃ©dio** (1 LLM call/15 arestas + embeddings) | Master Ã© ~60x mais eficiente em calls de API. |
| **Granularidade de Debug** | ğŸŸ¢ **Fina** (Log por agente, voto individual) | ğŸ”´ **Grossa** (Debate interno opaco) | Codex permite auditoria detalhada. |
| **Filosofia** | **Recall** (Descoberta) | **Precision** (SeguranÃ§a) | Codex: explorar; Master: certificar. |
| **Modelos Declarados (Fase 4)** | gpt-4o-mini + gpt-4o | gpt-5.1 | Codex: 2 modelos; Master: 1 modelo |

### ConclusÃ£o e RecomendaÃ§Ã£o

1.  **Ambiente de ProduÃ§Ã£o (Alunos Reais):** Recomenda-se o grafo **MASTER**. Embora mais esparso, a garantia de que as relaÃ§Ãµes sÃ£o tecnicamente corretas evita que o aluno receba recomendaÃ§Ãµes de estudo erradas ou confusas.
2.  **Ambiente de Pesquisa (Data Science):** Recomenda-se o grafo **CODEX**. A maior densidade permite testar algoritmos de GNN (Graph Neural Networks) com mais profundidade, mesmo que haja algum ruÃ­do.
