{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 4 - Validação Final (O Conselho dos Agentes)\n",
    "\n",
    "Esta é a etapa final e mais crítica do pipeline de extração do SINKT. Aqui, submetemos o grafo densificado a um rigoroso processo de auditoria e saneamento.\n",
    "\n",
    "**Objetivo:** Transformar o grafo \"bruto\" em um **Artefato de Conhecimento.\n",
    "\n",
    "## Arquitetura: A Mesa Redonda Virtual\n",
    "Em vez de múltiplos agentes desconexos, simulamos uma **Mesa Redonda** via Prompt Engineering com o **GPT-4o**. Cada aresta é debatida por 8 personas especializadas:\n",
    "\n",
    "1.  **Pedagogical Proponent (O Professor):** Defende valor didático.\n",
    "2.  **Technical Proponent (O Engenheiro):** Defende precisão técnica.\n",
    "3.  **Redundancy Critic (O Otimizador):** Caça duplicatas.\n",
    "4.  **Hallucination Hunter (O Cético):** Verifica veracidade.\n",
    "5.  **Structural Architect (O Topólogo):** Verifica hierarquias.\n",
    "6.  **The Ontologist (O Terminologista):** Padroniza termos.\n",
    "7.  **The Refactorer (O Reparador):** Propõe correções em vez de apenas deletar.\n",
    "8.  **The Judge (O Decisor):** Bate o martelo (KEEP, DISCARD, REFACTOR).\n",
    "\n",
    "## Pipeline de Processamento\n",
    "1.  **Carga:** Importar `enhanced_graph.json`.\n",
    "2.  **Debate:** Processamento em lote das arestas via LLM.\n",
    "3.  **Refatoração:** Aplicar as correções sugeridas pelo 'Refactorer'.\n",
    "4.  **Cirurgia Topológica:**\n",
    "    *   Remoção de Ciclos (DAG Enforcement).\n",
    "    *   Remoção de Nós Órfãos/Ilhas.\n",
    "5.  **Entrega:** Geração do `final_sinkt_graph.json` e relatório de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai networkx pydantic tqdm python-dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from typing import List, Literal, Optional\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuração do Modelo\n",
    "llm_judge = ChatOpenAI(model=\"gpt-5.1\", temperature=0)\n",
    "\n",
    "# --- NOVO DIRETÓRIO DE ENTRADA/SAÍDA ---\n",
    "INPUT_FOLDER = \"output/02_densification\"\n",
    "OUTPUT_FOLDER = \"output/03_final_audit\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "INPUT_FILE = f\"{INPUT_FOLDER}/enhanced_graph.json\"\n",
    "FINAL_FILE = f\"{OUTPUT_FOLDER}/final_sinkt_graph.json\"\n",
    "DEBATE_LOG = f\"{OUTPUT_FOLDER}/debate_log.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Carregados:\n",
      "   Conceitos: 204\n",
      "   Relações para Auditar: 219\n"
     ]
    }
   ],
   "source": [
    "## 1. Carregamento dos Dados\n",
    "\n",
    "def load_enhanced_graph():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        raise FileNotFoundError(f\"Arquivo {INPUT_FILE} não encontrado. Execute o notebook 3 primeiro.\")\n",
    "    \n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data['concepts'], data['relations']\n",
    "\n",
    "concepts, relations = load_enhanced_graph()\n",
    "\n",
    "print(f\"Dados Carregados:\")\n",
    "print(f\"   Conceitos: {len(concepts)}\")\n",
    "print(f\"   Relações para Auditar: {len(relations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. O Motor de Debate (Prompt Engineering)\n",
    "\n",
    "class EdgeVerdict(BaseModel):\n",
    "    source: str\n",
    "    target: str\n",
    "    verdict: Literal['KEEP', 'DISCARD', 'REFACTOR']\n",
    "    new_type: Optional[Literal['PREREQUISITE', 'PART_OF', 'IS_A', 'USE', 'RELATED_TO']] = Field(\n",
    "        description=\"Obrigatório se verdict='REFACTOR'. O tipo de relação corrigido e padronizado.\"\n",
    "    )\n",
    "    direction_correction: Optional[Literal['FORWARD', 'REVERSE']] = Field(\n",
    "        default='FORWARD', \n",
    "        description=\"Se 'REVERSE', indica que a seta deve ser invertida (Target -> Source).\"\n",
    "    )\n",
    "    confidence: float = Field(description=\"Nível de confiança no veredito (0.0 a 1.0).\")\n",
    "    reason: str = Field(description=\"Resumo executivo do debate. Ex: 'O Topólogo vetou pois criava ciclo, o Engenheiro sugeriu inversão'.\")\n",
    "\n",
    "class DebateOutput(BaseModel):\n",
    "    verdicts: List[EdgeVerdict]\n",
    "\n",
    "# --- CORREÇÃO: Inicializar o parser ---\n",
    "parser = PydanticOutputParser(pydantic_object=DebateOutput)\n",
    "\n",
    "debate_system_prompt = \"\"\"\n",
    "Você é o **SINKT ORACLE**, o autoridade suprema na validação de Grafos de Conhecimento Educacional para Linux.\n",
    "Sua missão é sanear o grafo final, garantindo integridade topológica e pedagógica.\n",
    "\n",
    "Para CADA relação recebida, você deve orquestrar um **Debate Virtual Rápido** entre 8 especialistas. Não pule etapas.\n",
    "\n",
    "### AS 8 PERSONAS DA MESA:\n",
    "\n",
    "1.  **Professor:** Foca na *Causalidade Pedagógica*. \"Aprender A desbloqueia B? Se não, descarte PREREQUISITE.\"\n",
    "2.  **Engenheiro:** Foca na *Verdade Técnica*. \"O comando 'ls' realmente faz parte do 'kernel'? Não! Descarte.\"\n",
    "3.  **Otimizador:** Caça *Redundâncias*. \"Se A é parte de B, e B é parte de C, precisamos de A->C? Talvez não.\"\n",
    "4.  **Cético:** Caça *Alucinações*. \"O conceito 'Linux' é um 'Comando'? Não. REFACTOR para 'Entidade'.\"\n",
    "5.  **Topólogo (CRÍTICO):** Protege o *DAG*. \"Essa relação cria um ciclo? A hierarquia flui do Geral para o Específico? Se A depende de B, B não pode depender de A.\"\n",
    "6.  **Terminologista:** Padroniza. \"Use 'PREREQUISITE' apenas para bloqueios de aprendizado. Use 'USE' para ferramentas.\"\n",
    "7.  **Reparador:** Tenta salvar a aresta. \"A relação está certa mas a direção errada? Inverta! O tipo está fraco? Fortaleça!\"\n",
    "8.  **JUIZ:** Sintetiza o debate e emite o veredito final com base na maioria qualificada e segurança técnica.\n",
    "\n",
    "### REGRAS DE DECISÃO (Guidelines):\n",
    "\n",
    "* **KEEP:** A relação é tecnicamente verdadeira, pedagogicamente útil e topologicamente segura.\n",
    "* **REFACTOR:**\n",
    "    * **Erro de Direção:** Ex: \"Shell\" PART_OF \"Bash\" (Errado) -> Inverter para \"Bash\" IS_A \"Shell\".\n",
    "    * **Erro de Tipo:** Ex: \"ls\" PREREQUISITE \"Terminal\" (Fraco) -> Mudar para \"Terminal\" USE \"ls\" ou vice-versa.\n",
    "* **DISCARD:**\n",
    "    * Alucinações (fatos falsos).\n",
    "    * Conexões muito genéricas que poluem o grafo (Ex: \"Linux\" RELATED_TO \"Computador\").\n",
    "    * Ciclos óbvios em pré-requisitos.\n",
    "\n",
    "### TIPOS CANÔNICOS PERMITIDOS:\n",
    "1.  **PREREQUISITE**: Dependência forte de aprendizado. (Nó A deve ser aprendido antes de B).\n",
    "2.  **PART_OF**: Composição mereológica. (Nó A é um componente do Nó B).\n",
    "3.  **IS_A**: Taxonomia/Herança. (Nó A é um tipo específico do Nó B).\n",
    "4.  **USE**: Relação funcional. (Ferramenta A utiliza/manipula Recurso B).\n",
    "5.  **RELATED_TO**: Último caso. Use apenas se houver relação forte mas que não cabe nas acima.\n",
    "\n",
    "Retorne o JSON estrito com a decisão final.\n",
    "\"\"\"\n",
    "debate_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", debate_system_prompt),\n",
    "        (\"user\", \"\"\"Aqui está o lote de arestas para julgamento.\n",
    "        \n",
    "        Lembre-se: O SINKT depende de um grafo limpo. Na dúvida, seja conservador.\n",
    "\n",
    "        ARESTAS:\n",
    "        {edges}\n",
    "\n",
    "        {format_instructions}\"\"\")\n",
    "    ])\n",
    "    | llm_judge \n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Sessão do Conselho Jedi (GPT-4o)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:11<02:13, 22.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Erro no batch 120: Failed to parse DebateOutput from completion {\"verdicts\": [{\"source\": \"help\", \"target\": \"ls\", \"verdict\": \"REFACTOR\", \"new_type\": \"USE\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.86, \"reason\": \"Professor e Terminologista apontam que o conceito é o mecanismo de ajuda genérico (‘help’ como ação/função) utilizando o comando específico ‘ls’ como exemplo; Engenheiro valida que é uma relação de uso funcional, não pré‑requisito. Topólogo vê que não cria ciclo relevante. JUIZ: manter aresta como USE está ok, apenas tipificando como USE canonical.\"}, {\"source\": \"help\", \"target\": \"--help\", \"verdict\": \"REFACTOR\", \"new_type\": \"RELATED_TO\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.78, \"reason\": \"Professor lembra que ‘help’ (conceito genérico de ajuda) não depende pedagogicamente de ‘--help’, é apenas uma forma concreta de obtê‑la. Engenheiro: ‘--help’ é uma opção de muitos comandos, não algo que ‘help’ use ativamente. Terminologista: não é PREREQUISITE nem USE; relação conceitual fraca porém real. Otimizador aceita RELATED_TO como elos conceituais mínimos. JUIZ: refatorar para RELATED_TO.\"}, {\"source\": \"type\", \"target\": \"help\", \"verdict\": \"REFACTOR\", \"new_type\": \"RELATED_TO\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.7, \"reason\": \"Debate gira em torno de saber se ‘type’ (comando bash que mostra o tipo de comando) usa ‘help’. Engenheiro nota que ‘type’ não invoca ‘help’; ele inspeciona como um nome de comando será interpretado. Professor considera que pedagógica e tecnicamente estão mais como tópicos correlatos na exploração de comandos. Terminologista descarta USE e PREREQUISITE. JUIZ: manter apenas como RELATED_TO, ou idealmente especializar ambos no futuro.\"}, {\"source\": \"--help\", \"target\": \"help\", \"verdict\": \"REFACTOR\", \"new_type\": \"RELATED_TO\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.84, \"reason\": \"Professor distingue que ‘--help’ é um modificador que pede ajuda, não algo que seja parte taxonômica de ‘help’. Engenheiro: semanticamente ‘--help’ produz help para um comando específico, mas não há relação de composição ou herança clara. Terminologista: melhor modelar como correlação conceitual. Topólogo não vê risco estrutural. JUIZ: REFACTOR para RELATED_TO.\"}, {\"source\": \"root\", \"target\": \"usuário de sistema\", \"verdict\": \"REFACTOR\", \"new_type\": \"IS_A\", \"direction_correction\": \"REVERSE\", \"confidence\": 0.95, \"reason\": \"Professor e Engenheiro concordam que ‘root’ é um tipo específico de ‘usuário de sistema’ (conta administrativa), não o contrário. Topólogo exige hierarquia do geral para o específico: ‘root’ deve ser descendente. Terminologista lembra a definição de IS_A: ‘A é um tipo de B’. Reparador propõe inverter. JUIZ: inverter a seta para ‘usuário de sistema’ IS_A ‘root’? Não; consenso é ‘root’ IS_A ‘usuário de sistema’, então direção deve ser REVERSE em relação à aresta recebida.\"}, {\"source\": \"sessão\", \"target\": \"usuário comum\", \"verdict\": \"DISCARD\", \"new_type\": null, \"direction_correction\": null, \"confidence\": 0.74, \"reason\": \"Professor nota que ‘sessão’ não é conceitualmente dependente de ‘usuário comum’; tanto root quanto usuários comuns possuem sessões. Engenheiro: semanticamente é uma relação ‘um usuário comum tem uma sessão’, que não se encaixa em PREREQUISITE, IS_A, PART_OF ou USE de forma limpa. Terminologista sugere RELATED_TO, mas Cético argumenta que é genérica demais e poluiria o grafo. JUIZ: aresta é fraca e pouco pedagógica, descartar.\"}, {\"source\": \"bash\", \"target\": \"variáveis\", \"verdict\": \"REFACTOR\", \"new_type\": \"USE\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.9, \"reason\": \"Professor e Engenheiro confirmam que o shell bash manipula e depende fortemente de variáveis de ambiente e de shell. Não é PREREQUISITE (conceito anterior) nem PART_OF (variáveis não são partes fixas do binário). Terminologista indica USE como relação funcional canônica. Topólogo: sem risco de ciclo. JUIZ: refatorar tipagem para USE canônico.\"}, {\"source\": \"aliases\", \"target\": \"bash\", \"verdict\": \"REFACTOR\", \"new_type\": \"USE\", \"direction_correction\": \"REVERSE\", \"confidence\": 0.92, \"reason\": \"Professor: pedagogicamente se ensina que ‘bash’ fornece o mecanismo de aliases; o conceito ‘aliases’ depende do shell, não o contrário. Engenheiro: aliases são uma funcionalidade interna de bash que usa bash como ambiente; bash não ‘usa’ aliases para existir. Reparador propõe inverter. Terminologista: uma funcionalidade específica ‘aliases’ USE ‘bash’ faz sentido (aliases precisam de bash para funcionar). JUIZ: inverter direção para ‘bash’ como target, mantendo tipo USE.\"}, {\"source\": \"comandos de sistema\", \"target\": \"bash\", \"verdict\": \"REFACTOR\", \"new_type\": \"USE\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.93, \"reason\": \"Engenheiro: ‘comandos de sistema’ (como ls, cp, mv) são tipicamente invocados a partir de um shell como bash; funcionalmente eles usam o shell como ambiente de entrada/saída. Professor: em um curso de bash, ver que ‘comandos de sistema’ USE ‘bash’ é didático. Terminologista: USE é aceitável, embora também se possa modelar como bash USE comandos; mas dado o enunciado, o Reparador avalia que a leitura ‘conjuntos de comandos usam bash para ser executados interativamente’ é razoável. Topólogo: não há ciclos. JUIZ: manter direção e padronizar tipo USE.\"}, {\"source\": \".bash_history\", \"target\": \"history\", \"verdict\": \"REFACTOR\", \"new_type\": \"PART_OF\", \"direction_correction\": \"REVERSE\", \"confidence\": 0.9, \"reason\": \"Engenheiro lembra que ‘.bash_history’ é um arquivo específico que armazena histórico de comandos do bash, enquanto ‘history’ é o conceito/funcionalidade de histórico (ou o builtin). Professor: pedagogicamente é ‘.bash_history’ como uma materialização do histórico. Topólogo: relação mereológica flui de parte para todo. Reparador propõe inverter para ‘.bash_history’ PART_OF ‘history’. Terminologista concorda com PART_OF. JUIZ: REFACTOR com direção REVERSE e tipo PART_OF.\"}, {\"source\": \"history\", \"target\": \"comandos de sistema\", \"verdict\": \"DISCARD\", \"new_type\": null, \"direction_correction\": null, \"confidence\": 0.8, \"reason\": \"Engenheiro: o builtin ‘history’ mostra comandos executados no shell, não é uma ferramenta que usa ‘comandos de sistema’ de forma estrutural; ele apenas lista entradas do histórico (que podem ser qualquer coisa digitada). Professor considera que a ligação é confusa didaticamente (pareceria que history depende de comandos de sistema para existir). Terminologista não vê encaixe claro em USE, PART_OF, IS_A ou PREREQUISITE; RELATED_TO também seria vago. Cético aponta risco de interpretação errada. JUIZ: descartar por fraqueza conceitual.\"}, {\"source\": \"/etc/issue\", \"target\": \"GNU/Linux\", \"verdict\": \"REFACTOR\", \"new_type\": \"PART_OF\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.94, \"reason\": \"Engenheiro: ‘/etc/issue’ é um arquivo de configuração de um sistema GNU/Linux tradicional, parte de sua configuração de login/identificação. Professor: faz sentido tratá‑lo como componente do sistema instalado. Topólogo: composição flui de arquivo específico (parte) ao sistema operacional (todo). Terminologista: PART_OF é o tipo correto. JUIZ: manter direção e padronizar como PART_OF.\"}, {\"source\": \"/etc/motd\", \"target\": \"GNU/Linux\", \"verdict\": \"REFACTOR\", \"new_type\": \"PART_OF\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.94, \"reason\": \"Engenheiro confirma que ‘/etc/motd’ é o arquivo de ‘message of the day’ em muitos sistemas GNU/Linux, parte da configuração do sistema. Professor: pedagogicamente visto como um componente textual do ambiente. Terminologista e Topólogo concordam com PART_OF do arquivo para o sistema. JUIZ: refatorar tipo para PART_OF mantendo a direção.\"}, {\"source\": \"/etc/issue.net\", \"target\": \"GNU/Linux\", \"verdict\": \"REFACTOR\", \"new_type\": \"PART_OF\", \"direction_correction\": \"FORWARD\", \"confidence\": 0.94, \"reason\": \"Engenheiro: ‘/etc/issue.net’ é similar a /etc/issue, usado por alguns serviços (como sshd) para banner de rede, sendo arquivo de configuração do sistema GNU/Linux. Professor e Terminologista: PART_OF expressa bem a relação arquivo‑sistema. Topólogo: nenhuma violação de DAG. JUIZ: REFACTOR apenas o tipo para PART_OF.\"}, {\"source\": \"whatis\", \"target\": \"apropos\", \"verdict\": \"RELATED_TO\", \"new_type\": null, \"direction_correction\": null, \"confidence\": 0.96, \"reason\": \"Professor observa que ‘whatis’ e ‘apropos’ são comandos de manual relacionados à documentação: whatis mostra descrições curtas, apropos pesquisa por palavras‑chave. Engenheiro: nenhum usa o outro diretamente; ambos consultam o banco de dados de manpages. Terminologista: não há IS_A, PART_OF nem PREREQUISITE; RELATED_TO é ideal. Otimizador não vê risco de redundância grave. JUIZ: manter aresta, interpretando o tipo já como RELATED_TO canônico.\"}]}. Got: 1 validation error for DebateOutput\n",
      "verdicts.14.verdict\n",
      "  Input should be 'KEEP', 'DISCARD' or 'REFACTOR' [type=literal_error, input_value='RELATED_TO', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/literal_error\n",
      "For troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:04<00:00, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultado do Debate ===\n",
      "Aprovadas: 145\n",
      "Descartadas: 59\n",
      "Refatoradas: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 3. Execução do Debate em Lote\n",
    "\n",
    "BATCH_SIZE = 15 # Tamanho do lote para o GPT-4o\n",
    "validated_edges = []\n",
    "discarded_count = 0\n",
    "refactored_count = 0\n",
    "\n",
    "print(f\"Iniciando Sessão do Conselho Jedi (GPT-4o)...\")\n",
    "\n",
    "# Preparar dados para o prompt\n",
    "edge_strings = [f\"{r['source']} -> {r.get('type', 'UNKNOWN')} -> {r['target']}\" for r in relations]\n",
    "\n",
    "for i in tqdm(range(0, len(edge_strings), BATCH_SIZE)):\n",
    "    batch = edge_strings[i:i+BATCH_SIZE]\n",
    "    \n",
    "    try:\n",
    "        result = debate_chain.invoke({\n",
    "            \"edges\": \"\\n\".join(batch),\n",
    "            \"format_instructions\": PydanticOutputParser(pydantic_object=DebateOutput).get_format_instructions()\n",
    "        })\n",
    "        \n",
    "        for v in result.verdicts:\n",
    "            if v.verdict == 'DISCARD':\n",
    "                discarded_count += 1\n",
    "            else:\n",
    "                final_type = v.new_type if v.new_type else 'RELATED_TO'\n",
    "                if v.verdict == 'REFACTOR':\n",
    "                    refactored_count += 1\n",
    "                \n",
    "                validated_edges.append({\n",
    "                    \"source\": v.source,\n",
    "                    \"target\": v.target,\n",
    "                    \"type\": final_type,\n",
    "                    \"reason\": v.reason\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro no batch {i}: {e}\")\n",
    "        # Fallback: Em caso de erro de API, mantemos as arestas originais como RELATED_TO por segurança\n",
    "        # ou descartamos. Aqui, vamos logar e pular para não paralisar.\n",
    "        pass\n",
    "\n",
    "print(\"\\n=== Resultado do Debate ===\")\n",
    "print(f\"Aprovadas: {len(validated_edges)}\")\n",
    "print(f\"Descartadas: {discarded_count}\")\n",
    "print(f\"Refatoradas: {refactored_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construindo grafo final com todas as arestas validadas...\n",
      "Grafo construído com sucesso.\n",
      "Nós: 204\n",
      "Arestas: 122\n"
     ]
    }
   ],
   "source": [
    "## 4. Construção do Grafo Final\n",
    "\n",
    "print(\"\\nConstruindo grafo final com todas as arestas validadas...\")\n",
    "\n",
    "# Construir Grafo NetworkX\n",
    "G = nx.DiGraph()\n",
    "for c in concepts:\n",
    "    G.add_node(c['nome'], tipo=c['tipo'], definicao=c['definicao'])\n",
    "\n",
    "# Adicionar arestas validadas\n",
    "# Mantemos todas as arestas aprovadas pelo Conselho, sem filtragem topológica (ciclos/ilhas permitidos)\n",
    "for r in validated_edges:\n",
    "    if G.has_node(r['source']) and G.has_node(r['target']):\n",
    "        G.add_edge(r['source'], r['target'], type=r['type'], reason=r['reason'])\n",
    "\n",
    "print(f\"Grafo construído com sucesso.\")\n",
    "print(f\"Nós: {G.number_of_nodes()}\")\n",
    "print(f\"Arestas: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "RELATÓRIO FINAL DO SINKT\n",
      "========================================\n",
      "Arquivo Salvo: output/03_final_audit/final_sinkt_graph.json\n",
      "Nós Finais: 204\n",
      "Arestas Finais: 122\n",
      "Densidade Final: 0.00295\n",
      "Ciclos Restantes: 6\n"
     ]
    }
   ],
   "source": [
    "## 5. Consolidação e Relatório Final\n",
    "\n",
    "# Preparar JSON Final\n",
    "final_concepts = []\n",
    "for n, attr in G.nodes(data=True):\n",
    "    final_concepts.append({\n",
    "        \"nome\": n,\n",
    "        \"tipo\": attr.get('tipo', 'Concept'),\n",
    "        \"definicao\": attr.get('definicao', '')\n",
    "    })\n",
    "\n",
    "final_relations = []\n",
    "for u, v, attr in G.edges(data=True):\n",
    "    final_relations.append({\n",
    "        \"source\": u,\n",
    "        \"target\": v,\n",
    "        \"type\": attr.get('type', 'RELATED_TO'),\n",
    "        \"reason\": attr.get('reason', 'Validated by Council')\n",
    "    })\n",
    "\n",
    "output_data = {\n",
    "    \"metadata\": {\n",
    "        \"pipeline\": \"SINKT v2 (Extraction -> Densification -> Council Validation)\",\n",
    "        \"model\": \"GPT-4o\",\n",
    "        \"nodes\": G.number_of_nodes(),\n",
    "        \"edges\": G.number_of_edges(),\n",
    "        \"density\": nx.density(G)\n",
    "    },\n",
    "    \"concepts\": final_concepts,\n",
    "    \"relations\": final_relations\n",
    "}\n",
    "\n",
    "with open(FINAL_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"RELATÓRIO FINAL DO SINKT\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Arquivo Salvo: {FINAL_FILE}\")\n",
    "print(f\"Nós Finais: {G.number_of_nodes()}\")\n",
    "print(f\"Arestas Finais: {G.number_of_edges()}\")\n",
    "print(f\"Densidade Final: {nx.density(G):.5f}\")\n",
    "print(f\"Ciclos Restantes: {len(list(nx.simple_cycles(G)))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
