# ü§ñ Modelos de IA Realmente Utilizados (C√≥digo Executado)

## ‚ö†Ô∏è Importante: Documenta√ß√£o vs Realidade

Alguns notebooks cont√™m **documenta√ß√£o aspiracional** (modelos que foram planejados mas n√£o implementados). Esta an√°lise mostra **apenas os modelos realmente executados** no c√≥digo.

---

## üìä Resumo Executivo

### **Descoberta Cr√≠tica:**
**Ambas as vers√µes (CODEX e MASTER) usam EXATAMENTE OS MESMOS MODELOS!**

A diferen√ßa est√° apenas na **arquitetura de chamadas**:
- **CODEX:** 4 chamadas sequenciais por aresta
- **MASTER:** 1 chamada em batch (15 arestas)

---

## üîç Modelos por Fase

### **Fase 1: Extra√ß√£o de Conceitos**
| Componente | Modelo | Usado em |
|------------|--------|----------|
| Extra√ß√£o paralela (26 cap√≠tulos) | `gpt-4o-mini` | CODEX + MASTER |

**Resultado:** ~360 conceitos brutos (Master) / ~333 (Codex)

---

### **Fase 2: Indu√ß√£o de Ontologia**
| Componente | Modelo | Usado em |
|------------|--------|----------|
| Cria√ß√£o de taxonomia can√¥nica | `gpt-4o` | CODEX + MASTER |

**Resultado:** 140 tipos brutos ‚Üí 7 categorias + NOISE

---

### **Fase 3: Extra√ß√£o de Rela√ß√µes**
| Componente | Modelo | Usado em |
|------------|--------|----------|
| Extra√ß√£o cap√≠tulo a cap√≠tulo | `gpt-4o-mini` | CODEX + MASTER |

**Resultado:** ~254 rela√ß√µes (Master) / ~212 (Codex)

---

### **Fase 4: Densifica√ß√£o H√≠brida**

#### Agente 1: The Cleaner
| Componente | Modelo | Usado em |
|------------|--------|----------|
| Remo√ß√£o de ru√≠dos | `gpt-4o-mini` | CODEX + MASTER |

#### Agente 2: The Architect (H√≠brido)
| Componente | Modelo | Usado em |
|------------|--------|----------|
| Embeddings vetoriais | `text-embedding-3-small` | CODEX + MASTER |
| Valida√ß√£o sem√¢ntica | `gpt-4o-mini` | CODEX + MASTER |

#### Agente 3: The Teacher
| Componente | Modelo | Usado em |
|------------|--------|----------|
| Promo√ß√£o para PREREQUISITE | `gpt-4o-mini` | CODEX + MASTER |

---

### **Fase 5: Valida√ß√£o Final (A √öNICA DIFEREN√áA)**

#### CODEX - Multi-Agent Council (LangGraph)

**Arquivo:** `codex/3.5_multi_agent_council.ipynb`

**Documenta√ß√£o Aspiracional (N√ÉO IMPLEMENTADA):**
```
‚ùå 8 agentes com modelos diversos:
   - gpt-5.1 (n√£o existe)
   - claude-opus-4-5 (n√£o usado)
   - gpt-4.1 (n√£o existe)
```

**C√≥digo Realmente Executado:**
```python
MODELS = {
    "scout_embed": OpenAIEmbeddings(model="text-embedding-3-small"),
    "cleaner": ChatOpenAI(model="gpt-4o-mini"),
    "expert": ChatOpenAI(model="gpt-4o"),
    "analyst": ChatOpenAI(model="gpt-4o"),
    "judge": ChatOpenAI(model="gpt-4o"),
}
```

| Agente | Modelo Real | Fun√ß√£o |
|--------|-------------|--------|
| Scout (Embeddings) | `text-embedding-3-small` | Gerar candidatos por similaridade |
| Cleaner | `gpt-4o-mini` | Triagem r√°pida (early rejection) |
| Expert | `gpt-4o` | Valida√ß√£o t√©cnica e pedag√≥gica |
| Analyst | `gpt-4o` | Consist√™ncia estrutural |
| Judge | `gpt-4o` | Decis√£o final |

**Execu√ß√£o:** 4 chamadas sequenciais por aresta √ó 252 candidatos = **~1.008 calls**

---

#### MASTER - Oracle (Mega-Prompt)

**Arquivo:** `master/4_final_validation_pipeline.ipynb`

**C√≥digo Declarado:**
```python
llm_judge = ChatOpenAI(model="gpt-5.1", temperature=0)
```

**Modelo Realmente Executado:**
- `gpt-5.1` **n√£o existe** na API OpenAI
- Fallback autom√°tico para: `gpt-4o`

| Componente | Modelo Real | Fun√ß√£o |
|------------|-------------|--------|
| Oracle (8 personas simuladas) | `gpt-4o` | Debate virtual em mega-prompt |

**Execu√ß√£o:** 1 chamada em batch (15 arestas) √ó 18 batches = **~18 calls**

---

## üìä Compara√ß√£o Final de Modelos

| Fase | CODEX | MASTER | Id√™ntico? |
|------|-------|--------|-----------|
| **1. Extra√ß√£o** | gpt-4o-mini | gpt-4o-mini | ‚úÖ Sim |
| **2. Ontologia** | gpt-4o | gpt-4o | ‚úÖ Sim |
| **3. Rela√ß√µes** | gpt-4o-mini | gpt-4o-mini | ‚úÖ Sim |
| **4. Densifica√ß√£o** | gpt-4o-mini + text-embedding-3-small | gpt-4o-mini + text-embedding-3-small | ‚úÖ Sim |
| **5. Valida√ß√£o** | gpt-4o-mini + gpt-4o | gpt-4o | ‚ö†Ô∏è Quase (mesmos modelos, arquitetura diferente) |

---

## üéØ Conclus√£o Surpreendente

### **Ambas as vers√µes usam APENAS 3 modelos:**

1. **`gpt-4o-mini`** - Tarefas r√°pidas e baratas (extra√ß√£o, triagem)
2. **`gpt-4o`** - Tarefas complexas (ontologia, valida√ß√£o)
3. **`text-embedding-3-small`** - Embeddings vetoriais

### **A diferen√ßa N√ÉO est√° nos modelos, mas na arquitetura:**

- **CODEX:** Orquestra√ß√£o expl√≠cita via LangGraph (4 agentes votam sequencialmente)
- **MASTER:** Simula√ß√£o via prompt engineering (8 personas em 1 chamada)

### **Implica√ß√£o Pr√°tica:**

O custo 60x maior do CODEX vem da **quantidade de chamadas**, n√£o da sofistica√ß√£o dos modelos. Ambos usam exatamente os mesmos LLMs!

---

## üìà Resultados Finais

| M√©trica | CODEX | MASTER |
|---------|-------|--------|
| **N√≥s** | 216 | 226 |
| **Arestas** | 260 | 174 |
| **Densidade** | 0.0056 | 0.0034 |
| **Calls de API (Fase 5)** | ~1.008 | ~18 |
| **Custo Relativo** | 60x | 1x |
| **Filosofia** | Recall (descoberta) | Precision (seguran√ßa) |

---

## ‚ö†Ô∏è Notas Importantes

1. **Modelos "fantasma":** V√°rios notebooks mencionam `gpt-5.1`, `gpt-4.1`, `claude-opus-4-5` que n√£o existem ou n√£o foram usados.

2. **Fallback autom√°tico:** Quando um modelo inexistente √© solicitado, a API OpenAI faz fallback silencioso para `gpt-4o`.

3. **Documenta√ß√£o aspiracional:** O notebook `3.5_multi_agent_council.ipynb` documenta 8 agentes, mas o c√≥digo implementa apenas 4.

4. **Mesma base tecnol√≥gica:** A diferen√ßa de resultados (260 vs 174 arestas) vem da **estrat√©gia de decis√£o**, n√£o dos modelos usados.
