# Relat√≥rio Final de Execu√ß√£o: Pipeline SINKT (Structure-Aware Inductive Knowledge Tracing)

Este relat√≥rio detalha a l√≥gica implementada nos pipelines de extra√ß√£o e densifica√ß√£o do grafo de conhecimento SINKT, bem como os resultados quantitativos e qualitativos da √∫ltima execu√ß√£o ("The Council Swarm").

---

## 1. Vis√£o Geral da Arquitetura

O projeto visa construir um grafo de conhecimento robusto para o dom√≠nio Linux, partindo de material did√°tico (PDF) at√© um grafo validado por m√∫ltiplos agentes de IA.

```mermaid
graph TD
    A[PDF Input] --> B(1. Concept Extraction)
    B --> C{Concepts Map}
    C --> D(2. Relation Extraction)
    D --> E{Initial Graph}
    E --> F(3.5 Multi-Agent Council)
    F --> G[Final Densified Graph]
    
    style F fill:#f9f,stroke:#333,stroke-width:2px
    style G fill:#bbf,stroke:#333,stroke-width:2px
```

---

## 2. Detalhamento dos Pipelines

### 2.1. Extra√ß√£o de Conceitos (`1_concept_extraction.ipynb`)

**Objetivo:** Identificar as entidades fundamentais do dom√≠nio (n√≥s do grafo).

*   **Entrada:** Arquivo PDF bruto.
*   **Modelos Utilizados:** 
    *   `gpt-4o-mini`: Para varredura inicial e extra√ß√£o de entidades em larga escala (custo-eficiente).
    *   `gpt-4o`: Para refinamento ontol√≥gico e categoriza√ß√£o complexa.
*   **Uso da LLM:**
    *   **Prompting:** Zero-shot extraction com defini√ß√£o de esquema JSON (lista de entidades com nome, tipo, defini√ß√£o).
    *   **Chunking:** O texto √© processado em janelas deslizantes para garantir que nenhum termo seja perdido na quebra de p√°ginas.
*   **Processamento:**
    1.  **Parsing:** Convers√£o de PDF para texto estruturado.
    2.  **LLM Extraction:** Uso de modelo de linguagem para identificar termos t√©cnicos (Comandos, Conceitos Te√≥ricos, Arquivos).
    3.  **Cleaning:** Deduplica√ß√£o e normaliza√ß√£o de nomes.
*   **Sa√≠da:** `concepts_map.json`.

### 2.2. Extra√ß√£o de Rela√ß√µes (`2_relation_extraction.ipynb`)

**Objetivo:** Mapear as conex√µes expl√≠citas no texto (arestas iniciais).

*   **Entrada:** `concepts_map.json` e texto do PDF.
*   **Modelos Utilizados:**
    *   `gpt-4o-mini`: Processamento massivo de pares de conceitos e janelas de contexto.
*   **Uso da LLM:**
    *   **Context-Aware Analysis:** A LLM recebe um conceito alvo e um trecho de texto (janela de contexto) onde ele aparece.
    *   **Relation Classification:** O modelo classifica se existe uma rela√ß√£o expl√≠cita no texto (ex: "X √© usado para Y") e extrai a evid√™ncia.
*   **Processamento:**
    1.  **Context Windowing:** Para cada conceito, busca-se o contexto onde ele aparece.
    2.  **LLM Relation Finding:** O modelo identifica rela√ß√µes expl√≠citas como "A √© parte de B" ou "A usa B".
*   **Sa√≠da:** `relations_initial.json` (O "Ground Truth" inicial).

### 2.3. An√°lise de Grafo (`2.5_graph_analytics.ipynb`)

**Objetivo:** Diagnosticar a sa√∫de do grafo inicial.

*   **M√©tricas:** Centralidade, detec√ß√£o de comunidades e identifica√ß√£o de "ilhas" (conceitos desconectados).
*   **Uso:** Serve como base para direcionar a densifica√ß√£o (quais √°reas precisam de mais conex√µes).

### 2.4. Densifica√ß√£o Multi-Agente (`3.5_multi_agent_council.ipynb`)

**Objetivo:** Inferir conex√µes impl√≠citas e validar novas arestas com rigor pedag√≥gico e t√©cnico. Este pipeline substituiu o notebook `3_multi_agent_densification.ipynb` por uma arquitetura de enxame (Swarm) mais robusta.

**Modelos & Agentes:**

| Agente | Modelo | Fun√ß√£o & M√©todo |
| :--- | :--- | :--- |
| **The Scout** | `text-embedding-3-small` | **Busca Vetorial:** Gera embeddings para todos os conceitos e calcula similaridade de cosseno para encontrar candidatos semanticamente pr√≥ximos (Threshold > 0.75). |
| **The Bridge** | `text-embedding-3-small` | **Heur√≠stica + Vetores:** Foca especificamente em conectar conceitos de cap√≠tulos distantes (Anti-Ilhas) com threshold adaptativo. |
| **The Cleaner** | `gpt-4o-mini` | **Filtragem R√°pida:** Recebe o par candidato e decide se √© "Lixo/Alucina√ß√£o" ou "Plaus√≠vel". Atua como *Gatekeeper* econ√¥mico. |
| **The Expert** | `gpt-4o` | **Deep Reasoning:** Simula um Engenheiro Linux S√™nior e um Pedagogo. Analisa a veracidade t√©cnica e a utilidade educacional. Pode sugerir novos tipos (`PREREQUISITE`, `USE`). |
| **The Analyst** | `gpt-4o` | **Structural Check:** Verifica consist√™ncia ontol√≥gica (ex: "Um comando n√£o pode ser parte de um arquivo") e topol√≥gica (ciclos). |
| **The Judge** | `gpt-4o` | **Synthesis:** Recebe os votos estruturados dos agentes anteriores e emite o veredito final (`KEEP`/`DISCARD`) em JSON estrito. |

**Arquitetura do Conselho (The Council):**

```mermaid
graph TD
    subgraph "Fase 1: Gera√ß√£o"
        Scout[üïµÔ∏è Scout (Vector Search)] -->|Candidatos| Queue
        Bridge[üåâ Bridge (Anti-Island)] -->|Candidatos| Queue
    end

    subgraph "Fase 2: O Conselho (LangGraph)"
        Queue --> Cleaner
        
        Cleaner{üßπ The Cleaner} -->|Reject| Judge
        Cleaner -->|Abstain/Pass| Expert
        
        Expert{üéì The Expert} -->|Approve/Modify| Analyst
        Expert -->|Reject| Analyst
        
        Analyst{üìê The Analyst} -->|Approve/Reject| Judge
        
        Judge{‚öñÔ∏è The Judge} -->|KEEP| FinalDB[(Final Graph)]
        Judge -->|DISCARD| Trash[Lixo]
    end
```

*   **The Scout/Bridge:** Usa embeddings vetoriais para encontrar conceitos semanticamente pr√≥ximos que n√£o estavam conectados explicitamente.
*   **The Cleaner:** Filtra alucina√ß√µes e erros de tipo √≥bvios.
*   **The Expert:** Valida a precis√£o t√©cnica ("Isso √© verdade no Linux?") e utilidade pedag√≥gica ("√â um pr√©-requisito?").
*   **The Analyst:** Verifica consist√™ncia topol√≥gica (evita ciclos e hierarquias imposs√≠veis).
*   **The Judge:** Toma a decis√£o final baseada nos votos.

---

## 3. Resultados da Execu√ß√£o

A execu√ß√£o do pipeline `3.5` foi conclu√≠da com sucesso, resultando em um grafo significativamente mais rico e validado.

### 3.1. M√©tricas Quantitativas

| M√©trica | Grafo Inicial | Grafo Final (P√≥s-Conselho) | Varia√ß√£o |
| :--- | :--- | :--- | :--- |
| **N√≥s (Conceitos)** | 216 | 216 | 0 |
| **Arestas (Rela√ß√µes)** | 207 | **260** | **+53 (+25.6%)** |
| **Densidade** | 0.0044 | 0.0056 | +27% |

### 3.2. Distribui√ß√£o de Tipos de Rela√ß√£o

O Conselho n√£o apenas adicionou arestas, mas refinou a tipologia:

*   **USE (Usa/Utiliza):** 86 (Maioria funcional)
*   **RELATED (Relacionado):** 75
*   **PART_OF (Parte de):** 44 (Hierarquia estrutural)
*   **RELATED_TO:** 25 (Novas conex√µes sem√¢nticas gen√©ricas)
*   **IS_A:** 18 (Taxonomia)
*   **PREREQUISITE:** 10 (Pedag√≥gico - **Novo**)

### 3.3. An√°lise Qualitativa (Decis√µes do Conselho)

Baseado nos logs de auditoria (`council_execution.log`), observamos o rigor do sistema:

#### ‚úÖ Arestas Aprovadas (KEEP)
O Conselho identificou rela√ß√µes l√≥gicas que n√£o estavam expl√≠citas no texto:
1.  **`pwconv` -> `pwunconv`** (Tipo: `PREREQUISITE`): Validado pelo Expert como comandos complementares de gerenciamento de senhas sombra.
2.  **`Sistema Operacional` -> `Divis√£o em camadas`** (Tipo: `PART_OF`): Validado como uma rela√ß√£o de composi√ß√£o fundamental te√≥rica.
3.  **`root` -> `Superusu√°rio (root)`** (Tipo: `RELATED_TO`): Reconhecimento de sinon√≠mia/conceito relacionado.

#### ‚ùå Arestas Rejeitadas (DISCARD)
O sistema bloqueou ru√≠do e alucina√ß√µes geradas pela busca vetorial:
1.  **`/tmp` -> `/boot`**: Rejeitado pelo Cleaner/Expert. Ambos s√£o diret√≥rios, mas n√£o t√™m rela√ß√£o direta de uso ou depend√™ncia.
2.  **`-B` -> `-h`**: Rejeitado. Flags de comando isoladas sem contexto n√£o devem ser conectadas aleatoriamente.
3.  **`cat` -> `echo`**: Rejeitado. Embora semanticamente pr√≥ximos (comandos de texto), n√£o possuem depend√™ncia funcional.

---

## 4. Conclus√£o

O pipeline demonstrou alta efic√°cia. A arquitetura **Multi-Agent Council** atingiu o equil√≠brio desejado entre **densifica√ß√£o** (aumento de 25% nas arestas) e **precis√£o** (rejei√ß√£o de pares sem sentido como `/tmp -> /boot`).

O grafo final (`output/03_council_execution/final_sinkt_graph_swarm.json`) est√° pronto para ser utilizado em aplica√ß√µes de Rastreamento de Conhecimento (Knowledge Tracing).
